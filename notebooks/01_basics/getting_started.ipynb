{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "60469aaf",
      "metadata": {},
      "source": [
        "# Getting Started with DSPy\n",
        "\n",
        "This notebook introduces the fundamental concepts of DSPy:\n",
        "- Setting up language models\n",
        "- Creating signatures\n",
        "- Using basic modules\n",
        "- Making predictions\n",
        "\n",
        "DSPy is a framework for algorithmically optimizing LM prompts and weights, especially when LMs are used one or more times within a pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0769b5fe",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the necessary libraries and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8623dea8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../../')\n",
        "\n",
        "import dspy\n",
        "from utils import setup_default_lm, print_step, print_result, print_error\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('../../.env')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "132e1443",
      "metadata": {},
      "source": [
        "## Language Model Configuration\n",
        "\n",
        "DSPy supports various language models. Let's configure one for our examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d2d8862",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Setting up Language Model\", \"Configuring DSPy with OpenAI gpt-4o\")\n",
        "\n",
        "try:\n",
        "    # Set up the language model\n",
        "    lm = setup_default_lm(provider=\"openai\", model=\"gpt-4o\", max_tokens=500)\n",
        "    \n",
        "    # Configure DSPy to use this model\n",
        "    dspy.configure(lm=lm)\n",
        "    \n",
        "    print_result(\"Language model configured successfully!\", \"Status\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print_error(f\"Failed to configure language model: {e}\")\n",
        "    print(\"Make sure you have set your OPENAI_API_KEY in the .env file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12c95140",
      "metadata": {},
      "source": [
        "## DSPy Signatures\n",
        "\n",
        "Signatures define the input/output behavior of your language model calls. They're like type hints for LM operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794b143e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Creating DSPy Signatures\", \"Defining input/output specifications\")\n",
        "\n",
        "# Simple question answering signature\n",
        "class QuestionAnswering(dspy.Signature):\n",
        "    \"\"\"Answer the given question with a concise and accurate response.\"\"\"\n",
        "    question = dspy.InputField(desc=\"The question to be answered\")\n",
        "    answer = dspy.OutputField(desc=\"A concise answer to the question\")\n",
        "\n",
        "# Text classification signature\n",
        "class SentimentClassification(dspy.Signature):\n",
        "    \"\"\"Classify the sentiment of the given text as positive, negative, or neutral.\"\"\"\n",
        "    text = dspy.InputField(desc=\"The text to classify\")\n",
        "    sentiment = dspy.OutputField(desc=\"The sentiment: positive, negative, or neutral\")\n",
        "\n",
        "print_result(\"Signatures created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e6aec35",
      "metadata": {},
      "source": [
        "## Basic Prediction Module\n",
        "\n",
        "The `Predict` module is the simplest way to use a signature with a language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bea3db9",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Using Predict Module\", \"Making basic predictions with our signatures\")\n",
        "\n",
        "# Create prediction modules\n",
        "qa_predictor = dspy.Predict(QuestionAnswering)\n",
        "sentiment_predictor = dspy.Predict(SentimentClassification)\n",
        "\n",
        "# Test question answering\n",
        "question = \"What is the capital of France?\"\n",
        "qa_result = qa_predictor(question=question)\n",
        "\n",
        "print_result(f\"Question: {question}\\nAnswer: {qa_result.answer}\", \"Question Answering\")\n",
        "\n",
        "# Test sentiment classification\n",
        "text = \"I absolutely love this new product! It's fantastic!\"\n",
        "sentiment_result = sentiment_predictor(text=text)\n",
        "\n",
        "print_result(f\"Text: {text}\\nSentiment: {sentiment_result.sentiment}\", \"Sentiment Classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af5e5e4",
      "metadata": {},
      "source": [
        "## Chain of Thought Reasoning\n",
        "\n",
        "The `ChainOfThought` module adds reasoning steps before providing the final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65686bb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Using ChainOfThought Module\", \"Adding reasoning steps to predictions\")\n",
        "\n",
        "# Create a math reasoning signature\n",
        "class MathReasoning(dspy.Signature):\n",
        "    \"\"\"Solve the mathematical problem step by step.\"\"\"\n",
        "    problem = dspy.InputField(desc=\"The mathematical problem to solve\")\n",
        "    reasoning = dspy.OutputField(desc=\"Step-by-step reasoning\")\n",
        "    answer = dspy.OutputField(desc=\"The final numerical answer\")\n",
        "\n",
        "# Use ChainOfThought for better reasoning\n",
        "math_cot = dspy.ChainOfThought(MathReasoning)\n",
        "\n",
        "# Test with a math problem\n",
        "problem = \"If a rectangle has a length of 8 meters and a width of 5 meters, what is its area?\"\n",
        "math_result = math_cot(problem=problem)\n",
        "\n",
        "print_result(f\"Problem: {problem}\\nReasoning: {math_result.reasoning}\\nAnswer: {math_result.answer}\", \"Math Reasoning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7449c6",
      "metadata": {},
      "source": [
        "## Custom DSPy Module\n",
        "\n",
        "You can create custom modules by subclassing `dspy.Module`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7909089a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Creating Custom Module\", \"Building a comprehensive question answering system\")\n",
        "\n",
        "class SmartQA(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Define signature for classification\n",
        "        class QuestionType(dspy.Signature):\n",
        "            \"\"\"Classify the type of question being asked.\"\"\"\n",
        "            question = dspy.InputField(desc=\"The question to classify\")\n",
        "            question_type = dspy.OutputField(desc=\"Type: factual, mathematical, creative, or analytical\")\n",
        "        \n",
        "        # Define signature for answering\n",
        "        class AnswerQuestion(dspy.Signature):\n",
        "            \"\"\"Answer the question based on its type.\"\"\"\n",
        "            question = dspy.InputField(desc=\"The question to answer\")\n",
        "            question_type = dspy.InputField(desc=\"The type of question\")\n",
        "            answer = dspy.OutputField(desc=\"A comprehensive answer\")\n",
        "        \n",
        "        # Initialize modules\n",
        "        self.classify_question = dspy.Predict(QuestionType)\n",
        "        self.answer_question = dspy.ChainOfThought(AnswerQuestion)\n",
        "    \n",
        "    def forward(self, question):\n",
        "        # First, classify the question type\n",
        "        classification = self.classify_question(question=question)\n",
        "        \n",
        "        # Then answer based on the type\n",
        "        answer = self.answer_question(\n",
        "            question=question,\n",
        "            question_type=classification.question_type\n",
        "        )\n",
        "        \n",
        "        return dspy.Prediction(\n",
        "            question_type=classification.question_type,\n",
        "            reasoning=answer.reasoning,\n",
        "            answer=answer.answer\n",
        "        )\n",
        "\n",
        "# Create and test the custom module\n",
        "smart_qa = SmartQA()\n",
        "\n",
        "test_questions = [\n",
        "    \"What is the speed of light?\",\n",
        "    \"If I have 10 apples and eat 3, how many do I have left?\",\n",
        "    \"Write a creative story about a robot learning to paint.\",\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    result = smart_qa(question=question)\n",
        "    print_result(\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"Type: {result.question_type}\\n\"\n",
        "        f\"Reasoning: {result.reasoning}\\n\"\n",
        "        f\"Answer: {result.answer}\",\n",
        "        f\"Smart QA Result\"\n",
        "    )\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a83f7b8",
      "metadata": {},
      "source": [
        "## Working with Examples\n",
        "\n",
        "DSPy uses `Example` objects to represent training and evaluation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23db54f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Working with Examples\", \"Creating and using DSPy Example objects\")\n",
        "\n",
        "# Create examples\n",
        "examples = [\n",
        "    dspy.Example(question=\"What is 2+2?\", answer=\"4\"),\n",
        "    dspy.Example(question=\"Who wrote Romeo and Juliet?\", answer=\"William Shakespeare\"),\n",
        "    dspy.Example(question=\"What is the largest planet?\", answer=\"Jupiter\"),\n",
        "]\n",
        "\n",
        "print_result(f\"Created {len(examples)} examples\")\n",
        "\n",
        "# Test our QA predictor on these examples\n",
        "print(\"Testing predictor on examples:\")\n",
        "for i, example in enumerate(examples, 1):\n",
        "    prediction = qa_predictor(question=example.question)\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    print(f\"Question: {example.question}\")\n",
        "    print(f\"Expected: {example.answer}\")\n",
        "    print(f\"Predicted: {prediction.answer}\")\n",
        "    print(f\"Match: {prediction.answer.lower().strip() == example.answer.lower().strip()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f324a2f7",
      "metadata": {},
      "source": [
        "## Inspecting LM Calls\n",
        "\n",
        "DSPy allows you to inspect the actual prompts and responses sent to the language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b475d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Inspecting LM History\", \"Looking at prompts and responses\")\n",
        "\n",
        "# Make a prediction to generate history\n",
        "result = qa_predictor(question=\"What is machine learning?\")\n",
        "\n",
        "# Inspect the history\n",
        "if hasattr(lm, 'history') and lm.history:\n",
        "    latest_call = lm.history[-1]\n",
        "    print_result(\n",
        "        f\"Prompt: {latest_call.get('prompt', 'N/A')}\\n\\n\"\n",
        "        f\"Response: {latest_call.get('response', 'N/A')}\",\n",
        "        \"Latest LM Call\"\n",
        "    )\n",
        "else:\n",
        "    print_result(\"History not available for this LM configuration\", \"Note\")\n",
        "\n",
        "print_result(f\"Answer: {result.answer}\", \"Final Result\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f53fa3ed",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we covered:\n",
        "\n",
        "1. **Language Model Setup**: How to configure DSPy with different LM providers\n",
        "2. **Signatures**: Defining input/output specifications for LM operations\n",
        "3. **Basic Modules**: Using `Predict` for simple predictions\n",
        "4. **Chain of Thought**: Adding reasoning steps with `ChainOfThought`\n",
        "5. **Custom Modules**: Creating complex workflows by subclassing `dspy.Module`\n",
        "6. **Examples**: Working with training/evaluation data\n",
        "7. **Inspection**: Understanding what's happening under the hood\n",
        "\n",
        "These are the fundamental building blocks for creating more sophisticated DSPy applications. In the next notebooks, we'll explore optimization, retrieval-augmented generation, and advanced techniques."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
