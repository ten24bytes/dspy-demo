{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9863f257",
      "metadata": {},
      "source": [
        "# Retrieval-Augmented Generation (RAG) with DSPy\n",
        "\n",
        "This notebook demonstrates how to build a RAG system using DSPy:\n",
        "- Setting up document retrieval\n",
        "- Creating RAG signatures and modules\n",
        "- Implementing different RAG strategies\n",
        "- Evaluating RAG performance\n",
        "\n",
        "RAG combines the power of information retrieval with language generation to provide accurate, contextual answers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c196c722",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "582292f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../../')\n",
        "\n",
        "import dspy\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "from utils import setup_default_lm, print_step, print_result, print_error\n",
        "from utils.datasets import get_sample_rag_documents\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('../../.env')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec6116ac",
      "metadata": {},
      "source": [
        "## Configure Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2530c234",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Configuring Language Model\", \"Setting up DSPy with OpenAI\")\n",
        "\n",
        "try:\n",
        "    lm = setup_default_lm(provider=\"openai\", model=\"gpt-4o\", max_tokens=1000)\n",
        "    dspy.configure(lm=lm)\n",
        "    print_result(\"Language model configured successfully!\")\n",
        "except Exception as e:\n",
        "    print_error(f\"Failed to configure language model: {e}\")\n",
        "    print(\"Make sure you have set your OPENAI_API_KEY in the .env file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d52cdee6",
      "metadata": {},
      "source": [
        "## Simple In-Memory Retriever\n",
        "\n",
        "Let's create a simple retriever that uses TF-IDF for document ranking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155d5e2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Creating Document Retriever\", \"Building a simple TF-IDF based retriever\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class SimpleRetriever:\n",
        "    def __init__(self, documents: List[str]):\n",
        "        self.documents = documents\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "        self.document_vectors = self.vectorizer.fit_transform(documents)\n",
        "    \n",
        "    def retrieve(self, query: str, k: int = 3) -> List[str]:\n",
        "        \"\"\"Retrieve top-k most relevant documents for the query.\"\"\"\n",
        "        query_vector = self.vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_vector, self.document_vectors)[0]\n",
        "        \n",
        "        # Get top-k document indices\n",
        "        top_indices = np.argsort(similarities)[::-1][:k]\n",
        "        \n",
        "        return [self.documents[i] for i in top_indices]\n",
        "\n",
        "# Load sample documents\n",
        "documents = get_sample_rag_documents()\n",
        "retriever = SimpleRetriever(documents)\n",
        "\n",
        "print_result(f\"Retriever initialized with {len(documents)} documents\")\n",
        "\n",
        "# Test the retriever\n",
        "test_query = \"What is machine learning?\"\n",
        "retrieved_docs = retriever.retrieve(test_query, k=2)\n",
        "\n",
        "print(f\"\\nQuery: {test_query}\")\n",
        "print(\"\\nRetrieved documents:\")\n",
        "for i, doc in enumerate(retrieved_docs, 1):\n",
        "    print(f\"{i}. {doc[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06d47ae5",
      "metadata": {},
      "source": [
        "## RAG Signatures\n",
        "\n",
        "Let's define signatures for our RAG system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51637bda",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Defining RAG Signatures\", \"Creating input/output specifications for RAG\")\n",
        "\n",
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer a question using the provided context documents.\"\"\"\n",
        "    context = dspy.InputField(desc=\"Relevant documents or passages\")\n",
        "    question = dspy.InputField(desc=\"The question to answer\")\n",
        "    answer = dspy.OutputField(desc=\"A comprehensive answer based on the context\")\n",
        "\n",
        "class GenerateAnswerWithCitation(dspy.Signature):\n",
        "    \"\"\"Answer a question using provided context and include citations.\"\"\"\n",
        "    context = dspy.InputField(desc=\"Relevant documents or passages\")\n",
        "    question = dspy.InputField(desc=\"The question to answer\")\n",
        "    answer = dspy.OutputField(desc=\"A comprehensive answer based on the context\")\n",
        "    citations = dspy.OutputField(desc=\"Citations or references to specific parts of the context\")\n",
        "\n",
        "print_result(\"RAG signatures defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeac305c",
      "metadata": {},
      "source": [
        "## Basic RAG Module\n",
        "\n",
        "Let's create a simple RAG module that retrieves documents and generates answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a604c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Creating Basic RAG Module\", \"Combining retrieval and generation\")\n",
        "\n",
        "class BasicRAG(dspy.Module):\n",
        "    def __init__(self, retriever, k=3):\n",
        "        super().__init__()\n",
        "        self.retriever = retriever\n",
        "        self.k = k\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "    \n",
        "    def forward(self, question):\n",
        "        # Retrieve relevant documents\n",
        "        context_docs = self.retriever.retrieve(question, k=self.k)\n",
        "        \n",
        "        # Combine contexts\n",
        "        context = \"\\n\\n\".join([f\"Document {i+1}: {doc}\" for i, doc in enumerate(context_docs)])\n",
        "        \n",
        "        # Generate answer\n",
        "        result = self.generate_answer(context=context, question=question)\n",
        "        \n",
        "        return dspy.Prediction(\n",
        "            context=context,\n",
        "            reasoning=result.reasoning,\n",
        "            answer=result.answer\n",
        "        )\n",
        "\n",
        "# Create and test the basic RAG system\n",
        "basic_rag = BasicRAG(retriever, k=2)\n",
        "\n",
        "test_questions = [\n",
        "    \"What is machine learning?\",\n",
        "    \"How does deep learning work?\",\n",
        "    \"What programming language is mentioned in the documents?\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    result = basic_rag(question=question)\n",
        "    print_result(\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        f\"Reasoning: {result.reasoning}\\n\\n\"\n",
        "        f\"Answer: {result.answer}\",\n",
        "        \"Basic RAG Result\"\n",
        "    )\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc2b4f9f",
      "metadata": {},
      "source": [
        "## Advanced RAG with Citations\n",
        "\n",
        "Let's create a more advanced RAG system that includes citations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d9dc6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Creating Advanced RAG with Citations\", \"Adding citation tracking to RAG\")\n",
        "\n",
        "class AdvancedRAG(dspy.Module):\n",
        "    def __init__(self, retriever, k=3):\n",
        "        super().__init__()\n",
        "        self.retriever = retriever\n",
        "        self.k = k\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswerWithCitation)\n",
        "    \n",
        "    def forward(self, question):\n",
        "        # Retrieve relevant documents\n",
        "        context_docs = self.retriever.retrieve(question, k=self.k)\n",
        "        \n",
        "        # Create numbered context with clear document boundaries\n",
        "        context_parts = []\n",
        "        for i, doc in enumerate(context_docs, 1):\n",
        "            context_parts.append(f\"[Document {i}]: {doc}\")\n",
        "        \n",
        "        context = \"\\n\\n\".join(context_parts)\n",
        "        \n",
        "        # Generate answer with citations\n",
        "        result = self.generate_answer(context=context, question=question)\n",
        "        \n",
        "        return dspy.Prediction(\n",
        "            context=context,\n",
        "            reasoning=result.reasoning,\n",
        "            answer=result.answer,\n",
        "            citations=result.citations,\n",
        "            retrieved_docs=context_docs\n",
        "        )\n",
        "\n",
        "# Create and test the advanced RAG system\n",
        "advanced_rag = AdvancedRAG(retriever, k=2)\n",
        "\n",
        "question = \"What is the relationship between machine learning and deep learning?\"\n",
        "result = advanced_rag(question=question)\n",
        "\n",
        "print_result(\n",
        "    f\"Question: {question}\\n\\n\"\n",
        "    f\"Reasoning: {result.reasoning}\\n\\n\"\n",
        "    f\"Answer: {result.answer}\\n\\n\"\n",
        "    f\"Citations: {result.citations}\",\n",
        "    \"Advanced RAG Result\"\n",
        ")\n",
        "\n",
        "print(\"\\nRetrieved Documents:\")\n",
        "for i, doc in enumerate(result.retrieved_docs, 1):\n",
        "    print(f\"Document {i}: {doc[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dd7fa5b",
      "metadata": {},
      "source": [
        "## Multi-Query RAG\n",
        "\n",
        "Let's create a RAG system that generates multiple queries to improve retrieval coverage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49a6a3fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Creating Multi-Query RAG\", \"Generating multiple queries for better retrieval\")\n",
        "\n",
        "class QueryExpansion(dspy.Signature):\n",
        "    \"\"\"Generate multiple related queries to improve document retrieval.\"\"\"\n",
        "    original_query = dspy.InputField(desc=\"The original question\")\n",
        "    expanded_queries = dspy.OutputField(desc=\"3-5 related queries that could help find relevant information\")\n",
        "\n",
        "class MultiQueryRAG(dspy.Module):\n",
        "    def __init__(self, retriever, k=2):\n",
        "        super().__init__()\n",
        "        self.retriever = retriever\n",
        "        self.k = k\n",
        "        self.expand_query = dspy.Predict(QueryExpansion)\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "    \n",
        "    def forward(self, question):\n",
        "        # Expand the original query\n",
        "        expansion_result = self.expand_query(original_query=question)\n",
        "        \n",
        "        # Parse expanded queries (simple split by newline)\n",
        "        expanded_queries = [q.strip() for q in expansion_result.expanded_queries.split('\\n') if q.strip()]\n",
        "        all_queries = [question] + expanded_queries[:3]  # Limit to avoid too many queries\n",
        "        \n",
        "        # Retrieve documents for each query\n",
        "        all_docs = []\n",
        "        for query in all_queries:\n",
        "            docs = self.retriever.retrieve(query, k=self.k)\n",
        "            all_docs.extend(docs)\n",
        "        \n",
        "        # Remove duplicates while preserving order\n",
        "        unique_docs = []\n",
        "        seen = set()\n",
        "        for doc in all_docs:\n",
        "            if doc not in seen:\n",
        "                unique_docs.append(doc)\n",
        "                seen.add(doc)\n",
        "        \n",
        "        # Limit to top documents\n",
        "        final_docs = unique_docs[:4]  # Limit to 4 documents\n",
        "        \n",
        "        # Create context\n",
        "        context = \"\\n\\n\".join([f\"Document {i+1}: {doc}\" for i, doc in enumerate(final_docs)])\n",
        "        \n",
        "        # Generate answer\n",
        "        result = self.generate_answer(context=context, question=question)\n",
        "        \n",
        "        return dspy.Prediction(\n",
        "            original_question=question,\n",
        "            expanded_queries=expanded_queries,\n",
        "            context=context,\n",
        "            reasoning=result.reasoning,\n",
        "            answer=result.answer,\n",
        "            retrieved_docs=final_docs\n",
        "        )\n",
        "\n",
        "# Create and test the multi-query RAG system\n",
        "multi_query_rag = MultiQueryRAG(retriever, k=2)\n",
        "\n",
        "question = \"How can AI help with data analysis?\"\n",
        "result = multi_query_rag(question=question)\n",
        "\n",
        "print_result(\n",
        "    f\"Original Question: {result.original_question}\\n\\n\"\n",
        "    f\"Expanded Queries: {result.expanded_queries}\\n\\n\"\n",
        "    f\"Reasoning: {result.reasoning}\\n\\n\"\n",
        "    f\"Answer: {result.answer}\",\n",
        "    \"Multi-Query RAG Result\"\n",
        ")\n",
        "\n",
        "print(f\"\\nTotal Retrieved Documents: {len(result.retrieved_docs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "360a1bb1",
      "metadata": {},
      "source": [
        "## RAG Evaluation\n",
        "\n",
        "Let's create some evaluation metrics for our RAG systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30daf297",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"RAG Evaluation\", \"Comparing different RAG approaches\")\n",
        "\n",
        "class AnswerQuality(dspy.Signature):\n",
        "    \"\"\"Evaluate the quality of an answer given a question and context.\"\"\"\n",
        "    question = dspy.InputField(desc=\"The original question\")\n",
        "    context = dspy.InputField(desc=\"The context used to generate the answer\")\n",
        "    answer = dspy.InputField(desc=\"The generated answer\")\n",
        "    quality_score = dspy.OutputField(desc=\"Quality score from 1-10 with explanation\")\n",
        "\n",
        "# Create evaluator\n",
        "evaluator = dspy.Predict(AnswerQuality)\n",
        "\n",
        "# Test questions for evaluation\n",
        "test_questions = [\n",
        "    \"What is machine learning?\",\n",
        "    \"How does deep learning differ from traditional programming?\"\n",
        "]\n",
        "\n",
        "print(\"Comparing RAG Systems:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for question in test_questions:\n",
        "    print(f\"\\nQuestion: {question}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # Test basic RAG\n",
        "    basic_result = basic_rag(question=question)\n",
        "    basic_eval = evaluator(\n",
        "        question=question,\n",
        "        context=basic_result.context[:500] + \"...\",  # Truncate for evaluation\n",
        "        answer=basic_result.answer\n",
        "    )\n",
        "    \n",
        "    # Test advanced RAG\n",
        "    advanced_result = advanced_rag(question=question)\n",
        "    advanced_eval = evaluator(\n",
        "        question=question,\n",
        "        context=advanced_result.context[:500] + \"...\",\n",
        "        answer=advanced_result.answer\n",
        "    )\n",
        "    \n",
        "    print(f\"Basic RAG Score: {basic_eval.quality_score}\")\n",
        "    print(f\"Advanced RAG Score: {advanced_eval.quality_score}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb5f9dea",
      "metadata": {},
      "source": [
        "## Interactive RAG Demo\n",
        "\n",
        "Let's create an interactive demo where you can ask questions and see how different RAG systems respond."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d7aee17",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_step(\"Interactive RAG Demo\", \"Try asking your own questions!\")\n",
        "\n",
        "def demo_rag_systems(question: str):\n",
        "    \"\"\"Demonstrate all RAG systems with a given question.\"\"\"\n",
        "    print(f\"Question: {question}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Basic RAG\n",
        "    print(\"\\n🔍 Basic RAG:\")\n",
        "    basic_result = basic_rag(question=question)\n",
        "    print(f\"Answer: {basic_result.answer}\")\n",
        "    \n",
        "    # Advanced RAG with Citations\n",
        "    print(\"\\n🎯 Advanced RAG with Citations:\")\n",
        "    advanced_result = advanced_rag(question=question)\n",
        "    print(f\"Answer: {advanced_result.answer}\")\n",
        "    if hasattr(advanced_result, 'citations') and advanced_result.citations:\n",
        "        print(f\"Citations: {advanced_result.citations}\")\n",
        "    \n",
        "    # Multi-Query RAG\n",
        "    print(\"\\n🚀 Multi-Query RAG:\")\n",
        "    multi_result = multi_query_rag(question=question)\n",
        "    print(f\"Answer: {multi_result.answer}\")\n",
        "    print(f\"Expanded Queries Used: {multi_result.expanded_queries[:100]}...\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Demo questions\n",
        "demo_questions = [\n",
        "    \"What is natural language processing?\",\n",
        "    \"How is data science related to machine learning?\"\n",
        "]\n",
        "\n",
        "for demo_question in demo_questions:\n",
        "    demo_rag_systems(demo_question)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# You can also try your own questions by uncommenting and modifying the line below:\n",
        "# demo_rag_systems(\"Your question here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be3cb97e",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we explored various RAG approaches with DSPy:\n",
        "\n",
        "1. **Simple Retriever**: Built a TF-IDF based document retriever\n",
        "2. **Basic RAG**: Combined retrieval with generation\n",
        "3. **Advanced RAG**: Added citation tracking for transparency\n",
        "4. **Multi-Query RAG**: Used query expansion for better retrieval coverage\n",
        "5. **Evaluation**: Created metrics to compare RAG system performance\n",
        "6. **Interactive Demo**: Tested different approaches with various questions\n",
        "\n",
        "Key takeaways:\n",
        "- RAG systems combine retrieval and generation for more accurate, contextual answers\n",
        "- Different retrieval strategies can significantly impact answer quality\n",
        "- Citations and transparency features improve trust in AI-generated answers\n",
        "- Query expansion can help retrieve more diverse and relevant information\n",
        "- Systematic evaluation helps compare and improve RAG approaches\n",
        "\n",
        "Next steps could include:\n",
        "- Using more sophisticated retrievers (e.g., dense embeddings, vector databases)\n",
        "- Implementing re-ranking mechanisms\n",
        "- Adding filtering and fact-checking capabilities\n",
        "- Optimizing the RAG pipeline with DSPy optimizers"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
