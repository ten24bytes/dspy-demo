{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cca4045",
   "metadata": {},
   "source": [
    "# Entity Extraction with DSPy\n",
    "\n",
    "This notebook demonstrates how to build named entity recognition (NER) systems using DSPy:\n",
    "- Extracting entities from unstructured text\n",
    "- Different entity types (person, organization, location, etc.)\n",
    "- Structured output formatting\n",
    "- Entity linking and relationship extraction\n",
    "\n",
    "Entity extraction is fundamental for information extraction, knowledge graph construction, and text analysis pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8b64a",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import dspy\n",
    "import json\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from utils import setup_default_lm, print_step, print_result, print_error\n",
    "from utils.datasets import get_sample_entity_data\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da2d0c",
   "metadata": {},
   "source": [
    "## Configure Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ecb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Configuring Language Model\", \"Setting up DSPy with OpenAI\")\n",
    "\n",
    "try:\n",
    "    lm = setup_default_lm(provider=\"openai\", model=\"gpt-3.5-turbo\", max_tokens=1000)\n",
    "    dspy.configure(lm=lm)\n",
    "    print_result(\"Language model configured successfully!\")\n",
    "except Exception as e:\n",
    "    print_error(f\"Failed to configure language model: {e}\")\n",
    "    print(\"Make sure you have set your OPENAI_API_KEY in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549b328",
   "metadata": {},
   "source": [
    "## Basic Named Entity Recognition\n",
    "\n",
    "Let's start with a simple entity extraction signature and module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d203e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Basic Entity Extraction\", \"Creating simple NER signature\")\n",
    "\n",
    "class BasicEntityExtraction(dspy.Signature):\n",
    "    \"\"\"Extract named entities from the given text.\"\"\"\n",
    "    text = dspy.InputField(desc=\"The input text to analyze\")\n",
    "    entities = dspy.OutputField(desc=\"List of entities found, each with type and text (format: 'entity_text (TYPE)')\")\n",
    "\n",
    "# Create basic entity extractor\n",
    "basic_extractor = dspy.Predict(BasicEntityExtraction)\n",
    "\n",
    "# Test with sample text\n",
    "sample_text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California. The company is now led by Tim Cook.\"\n",
    "\n",
    "result = basic_extractor(text=sample_text)\n",
    "\n",
    "print_result(\n",
    "    f\"Text: {sample_text}\\n\\n\"\n",
    "    f\"Entities: {result.entities}\",\n",
    "    \"Basic Entity Extraction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70a3c5",
   "metadata": {},
   "source": [
    "## Structured Entity Extraction\n",
    "\n",
    "Let's create a more structured approach that separates different entity types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Structured Entity Extraction\", \"Separating entities by type\")\n",
    "\n",
    "class StructuredEntityExtraction(dspy.Signature):\n",
    "    \"\"\"Extract and categorize named entities from text into specific types.\"\"\"\n",
    "    text = dspy.InputField(desc=\"The input text to analyze\")\n",
    "    persons = dspy.OutputField(desc=\"List of person names found in the text\")\n",
    "    organizations = dspy.OutputField(desc=\"List of organization names found in the text\")\n",
    "    locations = dspy.OutputField(desc=\"List of location names found in the text\")\n",
    "    dates = dspy.OutputField(desc=\"List of dates found in the text\")\n",
    "    other_entities = dspy.OutputField(desc=\"Other notable entities not fitting above categories\")\n",
    "\n",
    "# Create structured entity extractor\n",
    "structured_extractor = dspy.ChainOfThought(StructuredEntityExtraction)\n",
    "\n",
    "# Test with more complex text\n",
    "complex_text = \"\"\"\n",
    "On January 15, 2024, Microsoft CEO Satya Nadella announced a partnership with OpenAI \n",
    "during a conference in Seattle, Washington. The deal, worth $10 billion, will help \n",
    "accelerate AI development. Google's Sundar Pichai responded from Mountain View, California, \n",
    "expressing concerns about market competition.\n",
    "\"\"\"\n",
    "\n",
    "result = structured_extractor(text=complex_text)\n",
    "\n",
    "print_result(\n",
    "    f\"Text: {complex_text}\\n\\n\"\n",
    "    f\"Reasoning: {result.reasoning}\\n\\n\"\n",
    "    f\"Persons: {result.persons}\\n\"\n",
    "    f\"Organizations: {result.organizations}\\n\"\n",
    "    f\"Locations: {result.locations}\\n\"\n",
    "    f\"Dates: {result.dates}\\n\"\n",
    "    f\"Other Entities: {result.other_entities}\",\n",
    "    \"Structured Entity Extraction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7e6901",
   "metadata": {},
   "source": [
    "## Entity Relationship Extraction\n",
    "\n",
    "Let's extract not just entities but also relationships between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Entity Relationship Extraction\", \"Finding connections between entities\")\n",
    "\n",
    "class EntityRelationshipExtraction(dspy.Signature):\n",
    "    \"\"\"Extract entities and their relationships from text.\"\"\"\n",
    "    text = dspy.InputField(desc=\"The input text to analyze\")\n",
    "    entities = dspy.OutputField(desc=\"List of all entities with their types\")\n",
    "    relationships = dspy.OutputField(desc=\"List of relationships between entities (format: 'entity1 RELATION entity2')\")\n",
    "    key_facts = dspy.OutputField(desc=\"Key factual statements extracted from the text\")\n",
    "\n",
    "# Create relationship extractor\n",
    "relationship_extractor = dspy.ChainOfThought(EntityRelationshipExtraction)\n",
    "\n",
    "# Test with relationship-rich text\n",
    "relationship_text = \"\"\"\n",
    "Tesla, founded by Elon Musk, is headquartered in Austin, Texas. The company went public in 2010 \n",
    "and is listed on NASDAQ. Musk also serves as CEO of SpaceX, which is based in Hawthorne, California. \n",
    "SpaceX was established in 2002 and has contracts with NASA for space missions.\n",
    "\"\"\"\n",
    "\n",
    "result = relationship_extractor(text=relationship_text)\n",
    "\n",
    "print_result(\n",
    "    f\"Text: {relationship_text}\\n\\n\"\n",
    "    f\"Reasoning: {result.reasoning}\\n\\n\"\n",
    "    f\"Entities: {result.entities}\\n\\n\"\n",
    "    f\"Relationships: {result.relationships}\\n\\n\"\n",
    "    f\"Key Facts: {result.key_facts}\",\n",
    "    \"Entity Relationship Extraction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db014da8",
   "metadata": {},
   "source": [
    "## Domain-Specific Entity Extraction\n",
    "\n",
    "Let's create extractors for specific domains like medical, financial, or legal texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Domain-Specific Entity Extraction\", \"Medical and financial entity extraction\")\n",
    "\n",
    "class MedicalEntityExtraction(dspy.Signature):\n",
    "    \"\"\"Extract medical entities from clinical or health-related text.\"\"\"\n",
    "    text = dspy.InputField(desc=\"Medical or health-related text\")\n",
    "    conditions = dspy.OutputField(desc=\"Medical conditions, diseases, or symptoms mentioned\")\n",
    "    medications = dspy.OutputField(desc=\"Medications, drugs, or treatments mentioned\")\n",
    "    procedures = dspy.OutputField(desc=\"Medical procedures or tests mentioned\")\n",
    "    anatomy = dspy.OutputField(desc=\"Body parts, organs, or anatomical references\")\n",
    "    dosages = dspy.OutputField(desc=\"Dosage information or medical measurements\")\n",
    "\n",
    "class FinancialEntityExtraction(dspy.Signature):\n",
    "    \"\"\"Extract financial entities from business or financial text.\"\"\"\n",
    "    text = dspy.InputField(desc=\"Financial or business text\")\n",
    "    companies = dspy.OutputField(desc=\"Company names and stock symbols\")\n",
    "    currencies = dspy.OutputField(desc=\"Currency amounts and types\")\n",
    "    financial_instruments = dspy.OutputField(desc=\"Stocks, bonds, derivatives, etc.\")\n",
    "    financial_metrics = dspy.OutputField(desc=\"Revenue, profit, ratios, percentages\")\n",
    "    market_terms = dspy.OutputField(desc=\"Financial terms and jargon\")\n",
    "\n",
    "# Create domain-specific extractors\n",
    "medical_extractor = dspy.ChainOfThought(MedicalEntityExtraction)\n",
    "financial_extractor = dspy.ChainOfThought(FinancialEntityExtraction)\n",
    "\n",
    "# Test medical extraction\n",
    "medical_text = \"\"\"\n",
    "Patient presents with acute myocardial infarction. Administered 100mg aspirin and 5mg \n",
    "metoprolol. EKG shows ST elevation in leads II, III, aVF. Cardiac catheterization \n",
    "scheduled. Troponin levels elevated at 15.2 ng/mL. Blood pressure 140/90 mmHg.\n",
    "\"\"\"\n",
    "\n",
    "medical_result = medical_extractor(text=medical_text)\n",
    "\n",
    "print_result(\n",
    "    f\"Medical Text: {medical_text}\\n\\n\"\n",
    "    f\"Conditions: {medical_result.conditions}\\n\"\n",
    "    f\"Medications: {medical_result.medications}\\n\"\n",
    "    f\"Procedures: {medical_result.procedures}\\n\"\n",
    "    f\"Anatomy: {medical_result.anatomy}\\n\"\n",
    "    f\"Dosages: {medical_result.dosages}\",\n",
    "    \"Medical Entity Extraction\"\n",
    ")\n",
    "\n",
    "# Test financial extraction\n",
    "financial_text = \"\"\"\n",
    "Apple Inc. (AAPL) reported Q4 revenue of $119.58 billion, up 8% year-over-year. \n",
    "The company's gross margin improved to 45.96%. Tesla (TSLA) stock fell 3.2% after \n",
    "missing delivery targets. Bitcoin dropped below $45,000 amid regulatory concerns. \n",
    "The S&P 500 index closed at 4,750 points.\n",
    "\"\"\"\n",
    "\n",
    "financial_result = financial_extractor(text=financial_text)\n",
    "\n",
    "print_result(\n",
    "    f\"Financial Text: {financial_text}\\n\\n\"\n",
    "    f\"Companies: {financial_result.companies}\\n\"\n",
    "    f\"Currencies: {financial_result.currencies}\\n\"\n",
    "    f\"Financial Instruments: {financial_result.financial_instruments}\\n\"\n",
    "    f\"Financial Metrics: {financial_result.financial_metrics}\\n\"\n",
    "    f\"Market Terms: {financial_result.market_terms}\",\n",
    "    \"Financial Entity Extraction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb92c6a",
   "metadata": {},
   "source": [
    "## Entity Validation and Linking\n",
    "\n",
    "Let's add validation and confidence scoring to our entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41795531",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Entity Validation and Linking\", \"Adding confidence scores and validation\")\n",
    "\n",
    "class EntityValidation(dspy.Signature):\n",
    "    \"\"\"Validate and score extracted entities for accuracy and confidence.\"\"\"\n",
    "    text = dspy.InputField(desc=\"Original text\")\n",
    "    extracted_entities = dspy.InputField(desc=\"List of extracted entities\")\n",
    "    validated_entities = dspy.OutputField(desc=\"Validated entities with confidence scores (format: 'entity (TYPE) - confidence%')\")\n",
    "    potential_errors = dspy.OutputField(desc=\"Entities that might be incorrectly identified\")\n",
    "    missing_entities = dspy.OutputField(desc=\"Important entities that might have been missed\")\n",
    "\n",
    "class EntityLinking(dspy.Signature):\n",
    "    \"\"\"Link entities to external knowledge bases or provide additional context.\"\"\"\n",
    "    entity = dspy.InputField(desc=\"Entity to link\")\n",
    "    entity_type = dspy.InputField(desc=\"Type of entity (person, organization, etc.)\")\n",
    "    context = dspy.InputField(desc=\"Context from original text\")\n",
    "    linked_info = dspy.OutputField(desc=\"Additional information about the entity\")\n",
    "    disambiguation = dspy.OutputField(desc=\"Clarification if entity could refer to multiple things\")\n",
    "    confidence = dspy.OutputField(desc=\"Confidence in the linking (high/medium/low)\")\n",
    "\n",
    "# Create validation and linking modules\n",
    "entity_validator = dspy.ChainOfThought(EntityValidation)\n",
    "entity_linker = dspy.Predict(EntityLinking)\n",
    "\n",
    "# Complete entity extraction pipeline\n",
    "class CompleteEntityExtractor(dspy.Module):\n",
    "    \"\"\"Complete entity extraction pipeline with validation and linking.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.extractor = dspy.ChainOfThought(StructuredEntityExtraction)\n",
    "        self.validator = dspy.ChainOfThought(EntityValidation)\n",
    "        self.linker = dspy.Predict(EntityLinking)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # Step 1: Extract entities\n",
    "        extraction_result = self.extractor(text=text)\n",
    "        \n",
    "        # Step 2: Combine all entities\n",
    "        all_entities = []\n",
    "        if extraction_result.persons != \"None\" and extraction_result.persons:\n",
    "            all_entities.extend([f\"{p} (PERSON)\" for p in extraction_result.persons.split(\", \") if p.strip()])\n",
    "        if extraction_result.organizations != \"None\" and extraction_result.organizations:\n",
    "            all_entities.extend([f\"{o} (ORG)\" for o in extraction_result.organizations.split(\", \") if o.strip()])\n",
    "        if extraction_result.locations != \"None\" and extraction_result.locations:\n",
    "            all_entities.extend([f\"{l} (LOC)\" for l in extraction_result.locations.split(\", \") if l.strip()])\n",
    "        \n",
    "        # Step 3: Validate entities\n",
    "        validation_result = self.validator(\n",
    "            text=text,\n",
    "            extracted_entities=\", \".join(all_entities)\n",
    "        )\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            text=text,\n",
    "            extraction_reasoning=extraction_result.reasoning,\n",
    "            persons=extraction_result.persons,\n",
    "            organizations=extraction_result.organizations,\n",
    "            locations=extraction_result.locations,\n",
    "            dates=extraction_result.dates,\n",
    "            all_entities=all_entities,\n",
    "            validation_reasoning=validation_result.reasoning,\n",
    "            validated_entities=validation_result.validated_entities,\n",
    "            potential_errors=validation_result.potential_errors,\n",
    "            missing_entities=validation_result.missing_entities\n",
    "        )\n",
    "\n",
    "# Test complete pipeline\n",
    "complete_extractor = CompleteEntityExtractor()\n",
    "\n",
    "test_text = \"\"\"\n",
    "Barack Obama, the 44th President of the United States, was born in Hawaii. He served \n",
    "from 2009 to 2017 and was succeeded by Donald Trump. Obama graduated from Harvard Law School \n",
    "and taught at the University of Chicago. His wife Michelle Obama is also a Harvard graduate.\n",
    "\"\"\"\n",
    "\n",
    "complete_result = complete_extractor(text=test_text)\n",
    "\n",
    "print_result(\n",
    "    f\"Text: {test_text}\\n\\n\"\n",
    "    f\"Extraction Reasoning: {complete_result.extraction_reasoning}\\n\\n\"\n",
    "    f\"Extracted Entities:\\n\"\n",
    "    f\"- Persons: {complete_result.persons}\\n\"\n",
    "    f\"- Organizations: {complete_result.organizations}\\n\"\n",
    "    f\"- Locations: {complete_result.locations}\\n\"\n",
    "    f\"- Dates: {complete_result.dates}\\n\\n\"\n",
    "    f\"Validation Reasoning: {complete_result.validation_reasoning}\\n\\n\"\n",
    "    f\"Validated Entities: {complete_result.validated_entities}\\n\"\n",
    "    f\"Potential Errors: {complete_result.potential_errors}\\n\"\n",
    "    f\"Missing Entities: {complete_result.missing_entities}\",\n",
    "    \"Complete Entity Extraction Pipeline\"\n",
    ")\n",
    "\n",
    "# Test entity linking for specific entities\n",
    "print(\"\\n🔗 Entity Linking Examples:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "entities_to_link = [\n",
    "    (\"Barack Obama\", \"PERSON\", \"44th President of the United States\"),\n",
    "    (\"Harvard Law School\", \"ORGANIZATION\", \"prestigious law school\"),\n",
    "    (\"Hawaii\", \"LOCATION\", \"birth place of Barack Obama\")\n",
    "]\n",
    "\n",
    "for entity, entity_type, context in entities_to_link:\n",
    "    link_result = entity_linker(\n",
    "        entity=entity,\n",
    "        entity_type=entity_type,\n",
    "        context=context\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEntity: {entity} ({entity_type})\")\n",
    "    print(f\"Linked Info: {link_result.linked_info}\")\n",
    "    print(f\"Disambiguation: {link_result.disambiguation}\")\n",
    "    print(f\"Confidence: {link_result.confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37bd4d",
   "metadata": {},
   "source": [
    "## Entity Extraction Evaluation\n",
    "\n",
    "Let's evaluate our entity extraction system against ground truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6171f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Entity Extraction Evaluation\", \"Comparing against ground truth data\")\n",
    "\n",
    "def evaluate_entity_extraction(extractor, test_examples):\n",
    "    \"\"\"Evaluate entity extraction performance.\"\"\"\n",
    "    \n",
    "    def normalize_entity_list(entities_str):\n",
    "        \"\"\"Normalize entity string to list.\"\"\"\n",
    "        if not entities_str or entities_str.lower() in ['none', 'n/a', 'null']:\n",
    "            return set()\n",
    "        return set([e.strip().lower() for e in entities_str.split(',') if e.strip()])\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    num_examples = len(test_examples)\n",
    "    \n",
    "    print(\"Evaluation Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, example in enumerate(test_examples, 1):\n",
    "        # Extract entities\n",
    "        result = extractor(text=example.text)\n",
    "        \n",
    "        # Get predicted entities (combine all types)\n",
    "        predicted = set()\n",
    "        for field in ['persons', 'organizations', 'locations']:\n",
    "            if hasattr(result, field):\n",
    "                predicted.update(normalize_entity_list(getattr(result, field)))\n",
    "        \n",
    "        # Get ground truth entities\n",
    "        expected_entities = [e.split(' (')[0].lower() for e in example.entities]\n",
    "        expected = set(expected_entities)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        true_positives = len(predicted.intersection(expected))\n",
    "        false_positives = len(predicted - expected)\n",
    "        false_negatives = len(expected - predicted)\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "        \n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(f\"Text: {example.text[:100]}...\")\n",
    "        print(f\"Expected: {expected}\")\n",
    "        print(f\"Predicted: {predicted}\")\n",
    "        print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_precision = total_precision / num_examples\n",
    "    avg_recall = total_recall / num_examples\n",
    "    avg_f1 = total_f1 / num_examples\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Average Precision: {avg_precision:.3f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.3f}\")\n",
    "    print(f\"Average F1 Score: {avg_f1:.3f}\")\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "# Get test data\n",
    "test_examples = get_sample_entity_data()\n",
    "\n",
    "print(f\"Testing on {len(test_examples)} examples...\")\n",
    "\n",
    "# Evaluate our structured extractor\n",
    "precision, recall, f1 = evaluate_entity_extraction(structured_extractor, test_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039620e",
   "metadata": {},
   "source": [
    "## Batch Processing and Output Formatting\n",
    "\n",
    "Let's create utilities for processing multiple documents and formatting outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Batch Processing\", \"Processing multiple documents efficiently\")\n",
    "\n",
    "def batch_entity_extraction(extractor, texts: List[str], output_format=\"json\"):\n",
    "    \"\"\"Process multiple texts and return formatted results.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        print(f\"Processing document {i+1}/{len(texts)}...\")\n",
    "        \n",
    "        try:\n",
    "            result = extractor(text=text)\n",
    "            \n",
    "            if output_format == \"json\":\n",
    "                formatted_result = {\n",
    "                    \"document_id\": i+1,\n",
    "                    \"text\": text[:200] + \"...\" if len(text) > 200 else text,\n",
    "                    \"entities\": {\n",
    "                        \"persons\": result.persons.split(\", \") if result.persons and result.persons != \"None\" else [],\n",
    "                        \"organizations\": result.organizations.split(\", \") if result.organizations and result.organizations != \"None\" else [],\n",
    "                        \"locations\": result.locations.split(\", \") if result.locations and result.locations != \"None\" else [],\n",
    "                        \"dates\": result.dates.split(\", \") if result.dates and result.dates != \"None\" else []\n",
    "                    }\n",
    "                }\n",
    "            else:  # CSV format\n",
    "                formatted_result = {\n",
    "                    \"doc_id\": i+1,\n",
    "                    \"persons\": result.persons or \"\",\n",
    "                    \"organizations\": result.organizations or \"\",\n",
    "                    \"locations\": result.locations or \"\",\n",
    "                    \"dates\": result.dates or \"\"\n",
    "                }\n",
    "            \n",
    "            results.append(formatted_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing document {i+1}: {e}\")\n",
    "            results.append({\"document_id\": i+1, \"error\": str(e)})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test batch processing\n",
    "batch_texts = [\n",
    "    \"Microsoft announced that CEO Satya Nadella will speak at the Tech Conference in San Francisco next month.\",\n",
    "    \"The World Health Organization (WHO) reported new cases in Geneva, Switzerland, according to Dr. Maria Santos.\",\n",
    "    \"Amazon's Jeff Bezos stepped down as CEO in July 2021, passing leadership to Andy Jassy in Seattle.\",\n",
    "    \"The United Nations Security Council met in New York to discuss climate change initiatives with Secretary-General António Guterres.\"\n",
    "]\n",
    "\n",
    "batch_results = batch_entity_extraction(structured_extractor, batch_texts, output_format=\"json\")\n",
    "\n",
    "print_result(f\"Processed {len(batch_texts)} documents\", \"Batch Processing Complete\")\n",
    "\n",
    "# Display results\n",
    "for result in batch_results:\n",
    "    print(f\"\\nDocument {result['document_id']}:\")\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Entities: {json.dumps(result['entities'], indent=2)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Export to JSON file\n",
    "import json\n",
    "output_file = \"../../data/entity_extraction_results.json\"\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(batch_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3337e0cd",
   "metadata": {},
   "source": [
    "## Interactive Entity Extraction Demo\n",
    "\n",
    "Let's create an interactive demo where you can input text and see entity extraction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4181661",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Interactive Demo\", \"Try entity extraction with your own text!\")\n",
    "\n",
    "def interactive_entity_extraction(text: str):\n",
    "    \"\"\"Interactive entity extraction with detailed output.\"\"\"\n",
    "    print(f\"\\n🔍 Analyzing: {text}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Basic extraction\n",
    "    basic_result = basic_extractor(text=text)\n",
    "    print(f\"\\n📝 Basic Extraction:\")\n",
    "    print(f\"Entities: {basic_result.entities}\")\n",
    "    \n",
    "    # Structured extraction\n",
    "    structured_result = structured_extractor(text=text)\n",
    "    print(f\"\\n🏗️ Structured Extraction:\")\n",
    "    print(f\"Persons: {structured_result.persons}\")\n",
    "    print(f\"Organizations: {structured_result.organizations}\")\n",
    "    print(f\"Locations: {structured_result.locations}\")\n",
    "    print(f\"Dates: {structured_result.dates}\")\n",
    "    print(f\"Other: {structured_result.other_entities}\")\n",
    "    \n",
    "    # Relationship extraction\n",
    "    relationship_result = relationship_extractor(text=text)\n",
    "    print(f\"\\n🔗 Relationships:\")\n",
    "    print(f\"Relationships: {relationship_result.relationships}\")\n",
    "    print(f\"Key Facts: {relationship_result.key_facts}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Demo texts\n",
    "demo_texts = [\n",
    "    \"Apple Inc. announced that Tim Cook will meet with President Biden in Washington D.C. next Tuesday to discuss trade policies.\",\n",
    "    \"The research paper by Dr. Jane Smith from Stanford University was published in Nature magazine on March 15, 2024.\",\n",
    "    \"Netflix signed a $500 million deal with Sony Pictures Entertainment to stream movies exclusively starting January 2025.\"\n",
    "]\n",
    "\n",
    "print(\"Demo Entity Extraction Results:\")\n",
    "for i, demo_text in enumerate(demo_texts, 1):\n",
    "    print(f\"\\n🎯 Demo {i}:\")\n",
    "    interactive_entity_extraction(demo_text)\n",
    "\n",
    "# You can test with your own text by uncommenting and modifying the line below:\n",
    "# interactive_entity_extraction(\"Your text here...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ce4ae",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored comprehensive entity extraction techniques using DSPy:\n",
    "\n",
    "### Key Components Covered:\n",
    "\n",
    "1. **Basic Entity Extraction** - Simple NER with entity identification\n",
    "2. **Structured Extraction** - Categorizing entities by type (person, organization, location, date)\n",
    "3. **Relationship Extraction** - Finding connections and relationships between entities\n",
    "4. **Domain-Specific Extraction** - Specialized extractors for medical and financial texts\n",
    "5. **Entity Validation** - Confidence scoring and error detection\n",
    "6. **Entity Linking** - Connecting entities to external knowledge\n",
    "7. **Evaluation Framework** - Measuring extraction performance against ground truth\n",
    "8. **Batch Processing** - Efficient processing of multiple documents\n",
    "9. **Output Formatting** - Structured JSON and CSV output formats\n",
    "\n",
    "### Advanced Features:\n",
    "\n",
    "- **Chain of Thought Reasoning** - Explicit reasoning steps for complex extractions\n",
    "- **Multi-Step Pipelines** - Combining extraction, validation, and linking\n",
    "- **Domain Adaptation** - Specialized signatures for different text types\n",
    "- **Quality Metrics** - Precision, recall, and F1 scoring\n",
    "- **Error Handling** - Robust processing with error detection\n",
    "\n",
    "### Practical Applications:\n",
    "\n",
    "- **Information Extraction** - Extracting structured data from unstructured text\n",
    "- **Knowledge Graph Construction** - Building entity-relationship networks\n",
    "- **Document Processing** - Automated analysis of large document collections\n",
    "- **Content Analysis** - Understanding key entities in text content\n",
    "- **Data Enrichment** - Adding structured metadata to text data\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Fine-tuning** - Use DSPy optimizers to improve extraction accuracy\n",
    "- **Custom Domains** - Create specialized extractors for specific industries\n",
    "- **Real-time Processing** - Implement streaming entity extraction\n",
    "- **Integration** - Connect with databases and knowledge graphs\n",
    "- **Visualization** - Create entity relationship visualizations\n",
    "\n",
    "This comprehensive entity extraction system demonstrates how DSPy can be used to build sophisticated NLP pipelines that are both accurate and adaptable to different domains and requirements."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
