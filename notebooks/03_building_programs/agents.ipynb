{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79073452",
   "metadata": {},
   "source": [
    "# Building RAG as Agent with DSPy\n",
    "\n",
    "This notebook demonstrates how to build intelligent agents that combine Retrieval-Augmented Generation (RAG) with advanced reasoning capabilities using DSPy.\n",
    "\n",
    "## What You'll Learn:\n",
    "- Building agent-based RAG systems with DSPy\n",
    "- Combining retrieval with multi-step reasoning\n",
    "- Implementing tool-calling and external service integration\n",
    "- Creating adaptive and self-improving RAG agents\n",
    "- Managing memory and context across interactions\n",
    "\n",
    "Based on the DSPy tutorial: [Building RAG as Agent](https://dspy.ai/tutorials/agents/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bddb823",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import dspy\n",
    "from utils import setup_default_lm, print_step, print_result, print_error\n",
    "from utils.datasets import get_sample_rag_documents\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1f3cd",
   "metadata": {},
   "source": [
    "## Language Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Setting up Language Model\", \"Configuring DSPy for RAG Agent development\")\n",
    "\n",
    "try:\n",
    "    lm = setup_default_lm(provider=\"openai\", model=\"gpt-4o-mini\", max_tokens=2000)\n",
    "    dspy.configure(lm=lm)\n",
    "    print_result(\"Language model configured successfully!\", \"Status\")\n",
    "except Exception as e:\n",
    "    print_error(f\"Failed to configure language model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9bcc18",
   "metadata": {},
   "source": [
    "## Data Structures for RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AgentMemory:\n",
    "    \"\"\"Memory structure for the RAG agent.\"\"\"\n",
    "    conversation_history: List[Dict[str, str]]\n",
    "    retrieved_context: List[str]\n",
    "    reasoning_traces: List[str]\n",
    "    action_history: List[Dict[str, Any]]\n",
    "    learned_facts: List[str]\n",
    "\n",
    "@dataclass\n",
    "class AgentAction:\n",
    "    \"\"\"Represents an action the agent can take.\"\"\"\n",
    "    action_type: str  # 'retrieve', 'reason', 'synthesize', 'clarify'\n",
    "    parameters: Dict[str, Any]\n",
    "    confidence: float\n",
    "    rationale: str\n",
    "\n",
    "@dataclass\n",
    "class RetrievalResult:\n",
    "    \"\"\"Enhanced retrieval result with metadata.\"\"\"\n",
    "    content: str\n",
    "    relevance_score: float\n",
    "    source: str\n",
    "    timestamp: str\n",
    "    confidence: float\n",
    "\n",
    "print_result(\"Agent data structures defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e297530",
   "metadata": {},
   "source": [
    "## Document Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentRetriever:\n",
    "    \"\"\"Advanced retrieval system with semantic understanding.\"\"\"\n",
    "    \n",
    "    def __init__(self, documents: List[str]):\n",
    "        self.documents = documents\n",
    "        self.document_metadata = {}\n",
    "        self._initialize_metadata()\n",
    "    \n",
    "    def _initialize_metadata(self):\n",
    "        \"\"\"Initialize document metadata for better retrieval.\"\"\"\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            self.document_metadata[i] = {\n",
    "                'length': len(doc),\n",
    "                'keywords': self._extract_keywords(doc),\n",
    "                'topic': self._infer_topic(doc),\n",
    "                'complexity': self._estimate_complexity(doc)\n",
    "            }\n",
    "    \n",
    "    def _extract_keywords(self, text: str) -> List[str]:\n",
    "        \"\"\"Simple keyword extraction.\"\"\"\n",
    "        # In a real implementation, you'd use proper NLP libraries\n",
    "        words = text.lower().split()\n",
    "        return [word for word in words if len(word) > 4][:10]\n",
    "    \n",
    "    def _infer_topic(self, text: str) -> str:\n",
    "        \"\"\"Infer document topic.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        if 'machine learning' in text_lower or 'ai' in text_lower:\n",
    "            return 'technology'\n",
    "        elif 'science' in text_lower or 'research' in text_lower:\n",
    "            return 'science'\n",
    "        elif 'business' in text_lower or 'market' in text_lower:\n",
    "            return 'business'\n",
    "        else:\n",
    "            return 'general'\n",
    "    \n",
    "    def _estimate_complexity(self, text: str) -> float:\n",
    "        \"\"\"Estimate text complexity.\"\"\"\n",
    "        avg_word_length = np.mean([len(word) for word in text.split()])\n",
    "        return min(avg_word_length / 10.0, 1.0)\n",
    "    \n",
    "    def semantic_search(self, query: str, top_k: int = 3) -> List[RetrievalResult]:\n",
    "        \"\"\"Perform semantic search with enhanced scoring.\"\"\"\n",
    "        results = []\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        for i, doc in enumerate(self.documents):\n",
    "            # Simple similarity scoring (in practice, use embeddings)\n",
    "            doc_lower = doc.lower()\n",
    "            \n",
    "            # Keyword overlap\n",
    "            query_words = set(query_lower.split())\n",
    "            doc_words = set(doc_lower.split())\n",
    "            overlap = len(query_words.intersection(doc_words))\n",
    "            \n",
    "            # Basic relevance score\n",
    "            relevance = overlap / len(query_words) if query_words else 0\n",
    "            \n",
    "            # Boost score based on metadata\n",
    "            metadata = self.document_metadata[i]\n",
    "            if any(keyword in doc_lower for keyword in query_words):\n",
    "                relevance *= 1.2\n",
    "            \n",
    "            if relevance > 0:\n",
    "                results.append(RetrievalResult(\n",
    "                    content=doc,\n",
    "                    relevance_score=relevance,\n",
    "                    source=f\"doc_{i}\",\n",
    "                    timestamp=datetime.now().isoformat(),\n",
    "                    confidence=min(relevance * 0.8, 1.0)\n",
    "                ))\n",
    "        \n",
    "        # Sort by relevance and return top_k\n",
    "        results.sort(key=lambda x: x.relevance_score, reverse=True)\n",
    "        return results[:top_k]\n",
    "    \n",
    "    def adaptive_retrieve(self, query: str, context: List[str], memory: AgentMemory) -> List[RetrievalResult]:\n",
    "        \"\"\"Adaptive retrieval that considers context and memory.\"\"\"\n",
    "        # Expand query based on conversation history\n",
    "        expanded_query = query\n",
    "        if memory.conversation_history:\n",
    "            recent_context = \" \".join([msg['content'] for msg in memory.conversation_history[-3:]])\n",
    "            expanded_query = f\"{query} {recent_context}\"\n",
    "        \n",
    "        # Get initial results\n",
    "        results = self.semantic_search(expanded_query, top_k=5)\n",
    "        \n",
    "        # Filter out already retrieved content\n",
    "        seen_content = set(memory.retrieved_context)\n",
    "        filtered_results = [r for r in results if r.content not in seen_content]\n",
    "        \n",
    "        return filtered_results[:3]\n",
    "\n",
    "# Initialize retriever with sample documents\n",
    "documents = get_sample_rag_documents()\n",
    "retriever = IntelligentRetriever(documents)\n",
    "\n",
    "print_result(f\"Initialized retriever with {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfcafdc",
   "metadata": {},
   "source": [
    "## RAG Agent Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366af436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryAnalysis(dspy.Signature):\n",
    "    \"\"\"Analyze user query to determine optimal agent strategy.\"\"\"\n",
    "    \n",
    "    query = dspy.InputField(desc=\"User's question or request\")\n",
    "    conversation_context = dspy.InputField(desc=\"Previous conversation context\")\n",
    "    \n",
    "    query_type = dspy.OutputField(desc=\"Type of query: factual, analytical, creative, or procedural\")\n",
    "    complexity_level = dspy.OutputField(desc=\"Complexity level: simple, moderate, or complex\")\n",
    "    required_actions = dspy.OutputField(desc=\"List of actions needed to answer the query\")\n",
    "    retrieval_strategy = dspy.OutputField(desc=\"Best retrieval strategy for this query\")\n",
    "\n",
    "class ActionPlanning(dspy.Signature):\n",
    "    \"\"\"Plan the sequence of actions to answer a query.\"\"\"\n",
    "    \n",
    "    query = dspy.InputField(desc=\"User's question\")\n",
    "    query_analysis = dspy.InputField(desc=\"Analysis of the query\")\n",
    "    available_context = dspy.InputField(desc=\"Currently available context and information\")\n",
    "    \n",
    "    action_plan = dspy.OutputField(desc=\"Step-by-step plan to answer the query\")\n",
    "    priority_actions = dspy.OutputField(desc=\"Most important actions to take first\")\n",
    "    fallback_strategy = dspy.OutputField(desc=\"Alternative approach if primary plan fails\")\n",
    "\n",
    "class ContextualRetrieval(dspy.Signature):\n",
    "    \"\"\"Perform contextual document retrieval.\"\"\"\n",
    "    \n",
    "    query = dspy.InputField(desc=\"Search query\")\n",
    "    context = dspy.InputField(desc=\"Current conversation context\")\n",
    "    retrieval_strategy = dspy.InputField(desc=\"Retrieval strategy to use\")\n",
    "    \n",
    "    search_queries = dspy.OutputField(desc=\"Optimized search queries for retrieval\")\n",
    "    relevance_criteria = dspy.OutputField(desc=\"Criteria for evaluating document relevance\")\n",
    "    expected_answer_type = dspy.OutputField(desc=\"Type of information expected in the answer\")\n",
    "\n",
    "class InformationSynthesis(dspy.Signature):\n",
    "    \"\"\"Synthesize information from multiple sources into a coherent response.\"\"\"\n",
    "    \n",
    "    query = dspy.InputField(desc=\"Original user query\")\n",
    "    retrieved_docs = dspy.InputField(desc=\"Retrieved documents and information\")\n",
    "    conversation_memory = dspy.InputField(desc=\"Relevant conversation history\")\n",
    "    \n",
    "    synthesized_answer = dspy.OutputField(desc=\"Comprehensive answer synthesized from sources\")\n",
    "    confidence_level = dspy.OutputField(desc=\"Confidence level in the answer\")\n",
    "    information_gaps = dspy.OutputField(desc=\"Identified gaps in available information\")\n",
    "    follow_up_suggestions = dspy.OutputField(desc=\"Suggested follow-up questions or actions\")\n",
    "\n",
    "class MemoryManagement(dspy.Signature):\n",
    "    \"\"\"Manage agent memory and learning.\"\"\"\n",
    "    \n",
    "    current_interaction = dspy.InputField(desc=\"Current query and response\")\n",
    "    existing_memory = dspy.InputField(desc=\"Current agent memory state\")\n",
    "    interaction_outcome = dspy.InputField(desc=\"Success/failure of the interaction\")\n",
    "    \n",
    "    memory_updates = dspy.OutputField(desc=\"Updates to make to agent memory\")\n",
    "    learned_patterns = dspy.OutputField(desc=\"New patterns or facts learned\")\n",
    "    memory_consolidation = dspy.OutputField(desc=\"How to consolidate and organize memory\")\n",
    "\n",
    "print_result(\"RAG Agent signatures defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc928ea",
   "metadata": {},
   "source": [
    "## Advanced RAG Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedRAGAgent(dspy.Module):\n",
    "    \"\"\"Advanced RAG agent with multi-step reasoning and memory.\"\"\"\n",
    "    \n",
    "    def __init__(self, retriever: IntelligentRetriever):\n",
    "        super().__init__()\n",
    "        self.retriever = retriever\n",
    "        \n",
    "        # Initialize DSPy modules\n",
    "        self.query_analyzer = dspy.ChainOfThought(QueryAnalysis)\n",
    "        self.action_planner = dspy.ChainOfThought(ActionPlanning)\n",
    "        self.contextual_retriever = dspy.ChainOfThought(ContextualRetrieval)\n",
    "        self.information_synthesizer = dspy.ChainOfThought(InformationSynthesis)\n",
    "        self.memory_manager = dspy.ChainOfThought(MemoryManagement)\n",
    "        \n",
    "        # Agent memory\n",
    "        self.memory = AgentMemory(\n",
    "            conversation_history=[],\n",
    "            retrieved_context=[],\n",
    "            reasoning_traces=[],\n",
    "            action_history=[],\n",
    "            learned_facts=[]\n",
    "        )\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.interaction_count = 0\n",
    "        self.success_rate = 0.0\n",
    "    \n",
    "    def forward(self, query: str) -> dspy.Prediction:\n",
    "        \"\"\"Main agent reasoning loop.\"\"\"\n",
    "        \n",
    "        self.interaction_count += 1\n",
    "        \n",
    "        # Step 1: Analyze the query\n",
    "        conversation_context = self._get_conversation_context()\n",
    "        query_analysis = self.query_analyzer(\n",
    "            query=query,\n",
    "            conversation_context=conversation_context\n",
    "        )\n",
    "        \n",
    "        # Step 2: Plan actions\n",
    "        available_context = self._get_available_context()\n",
    "        action_plan = self.action_planner(\n",
    "            query=query,\n",
    "            query_analysis=f\"Type: {query_analysis.query_type}, Complexity: {query_analysis.complexity_level}\",\n",
    "            available_context=available_context\n",
    "        )\n",
    "        \n",
    "        # Step 3: Execute retrieval strategy\n",
    "        retrieval_result = self._execute_retrieval(query, query_analysis, action_plan)\n",
    "        \n",
    "        # Step 4: Synthesize information\n",
    "        synthesis = self.information_synthesizer(\n",
    "            query=query,\n",
    "            retrieved_docs=retrieval_result['formatted_docs'],\n",
    "            conversation_memory=conversation_context\n",
    "        )\n",
    "        \n",
    "        # Step 5: Update memory\n",
    "        self._update_memory(query, synthesis, query_analysis)\n",
    "        \n",
    "        # Step 6: Evaluate and learn\n",
    "        self._evaluate_interaction(query, synthesis)\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            answer=synthesis.synthesized_answer,\n",
    "            confidence=synthesis.confidence_level,\n",
    "            query_type=query_analysis.query_type,\n",
    "            action_plan=action_plan.action_plan,\n",
    "            retrieved_sources=retrieval_result['sources'],\n",
    "            information_gaps=synthesis.information_gaps,\n",
    "            follow_up_suggestions=synthesis.follow_up_suggestions,\n",
    "            reasoning_trace=self._get_reasoning_trace(query_analysis, action_plan, synthesis)\n",
    "        )\n",
    "    \n",
    "    def _get_conversation_context(self) -> str:\n",
    "        \"\"\"Get recent conversation context.\"\"\"\n",
    "        if not self.memory.conversation_history:\n",
    "            return \"No previous conversation context.\"\n",
    "        \n",
    "        recent_history = self.memory.conversation_history[-3:]\n",
    "        context = \"\\n\".join([\n",
    "            f\"{msg['role']}: {msg['content']}\"\n",
    "            for msg in recent_history\n",
    "        ])\n",
    "        return context\n",
    "    \n",
    "    def _get_available_context(self) -> str:\n",
    "        \"\"\"Get currently available context information.\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        if self.memory.retrieved_context:\n",
    "            context_parts.append(f\"Retrieved context: {len(self.memory.retrieved_context)} documents\")\n",
    "        \n",
    "        if self.memory.learned_facts:\n",
    "            context_parts.append(f\"Learned facts: {len(self.memory.learned_facts)} items\")\n",
    "        \n",
    "        if self.memory.reasoning_traces:\n",
    "            context_parts.append(f\"Previous reasoning: {len(self.memory.reasoning_traces)} traces\")\n",
    "        \n",
    "        return \"; \".join(context_parts) if context_parts else \"No available context.\"\n",
    "    \n",
    "    def _execute_retrieval(self, query: str, query_analysis, action_plan) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the retrieval strategy.\"\"\"\n",
    "        \n",
    "        # Get retrieval parameters\n",
    "        retrieval_params = self.contextual_retriever(\n",
    "            query=query,\n",
    "            context=self._get_conversation_context(),\n",
    "            retrieval_strategy=query_analysis.retrieval_strategy\n",
    "        )\n",
    "        \n",
    "        # Perform adaptive retrieval\n",
    "        retrieved_docs = self.retriever.adaptive_retrieve(query, [], self.memory)\n",
    "        \n",
    "        # Format documents for synthesis\n",
    "        formatted_docs = \"\\n\\n\".join([\n",
    "            f\"Source {i+1} (relevance: {doc.relevance_score:.2f}):\\n{doc.content}\"\n",
    "            for i, doc in enumerate(retrieved_docs)\n",
    "        ])\n",
    "        \n",
    "        # Update memory with retrieved context\n",
    "        for doc in retrieved_docs:\n",
    "            if doc.content not in self.memory.retrieved_context:\n",
    "                self.memory.retrieved_context.append(doc.content)\n",
    "        \n",
    "        return {\n",
    "            'formatted_docs': formatted_docs,\n",
    "            'sources': [doc.source for doc in retrieved_docs],\n",
    "            'retrieval_params': retrieval_params\n",
    "        }\n",
    "    \n",
    "    def _update_memory(self, query: str, synthesis, query_analysis):\n",
    "        \"\"\"Update agent memory with new interaction.\"\"\"\n",
    "        \n",
    "        # Add to conversation history\n",
    "        self.memory.conversation_history.append({\n",
    "            'role': 'user',\n",
    "            'content': query,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        self.memory.conversation_history.append({\n",
    "            'role': 'assistant',\n",
    "            'content': synthesis.synthesized_answer,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Add reasoning trace\n",
    "        reasoning_trace = f\"Query: {query} | Type: {query_analysis.query_type} | Answer: {synthesis.synthesized_answer[:100]}...\"\n",
    "        self.memory.reasoning_traces.append(reasoning_trace)\n",
    "        \n",
    "        # Use memory manager for advanced updates\n",
    "        memory_update = self.memory_manager(\n",
    "            current_interaction=f\"Q: {query}\\nA: {synthesis.synthesized_answer}\",\n",
    "            existing_memory=str(len(self.memory.learned_facts)),\n",
    "            interaction_outcome=\"success\" if float(synthesis.confidence_level.split('%')[0] if '%' in synthesis.confidence_level else '0') > 70 else \"partial\"\n",
    "        )\n",
    "        \n",
    "        # Apply memory updates\n",
    "        if hasattr(memory_update, 'learned_patterns') and memory_update.learned_patterns:\n",
    "            self.memory.learned_facts.append(memory_update.learned_patterns)\n",
    "    \n",
    "    def _evaluate_interaction(self, query: str, synthesis):\n",
    "        \"\"\"Evaluate and learn from the interaction.\"\"\"\n",
    "        \n",
    "        # Simple confidence-based evaluation\n",
    "        try:\n",
    "            confidence_value = float(synthesis.confidence_level.split('%')[0] if '%' in synthesis.confidence_level else synthesis.confidence_level)\n",
    "            success = confidence_value > 70\n",
    "        except:\n",
    "            success = len(synthesis.synthesized_answer) > 50  # Fallback heuristic\n",
    "        \n",
    "        # Update success rate\n",
    "        current_success = 1.0 if success else 0.0\n",
    "        self.success_rate = (self.success_rate * (self.interaction_count - 1) + current_success) / self.interaction_count\n",
    "        \n",
    "        # Log action\n",
    "        self.memory.action_history.append({\n",
    "            'query': query,\n",
    "            'success': success,\n",
    "            'confidence': synthesis.confidence_level,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    def _get_reasoning_trace(self, query_analysis, action_plan, synthesis) -> str:\n",
    "        \"\"\"Generate a reasoning trace for transparency.\"\"\"\n",
    "        \n",
    "        trace_parts = [\n",
    "            f\"1. Query Analysis: {query_analysis.query_type} query with {query_analysis.complexity_level} complexity\",\n",
    "            f\"2. Action Planning: {action_plan.action_plan}\",\n",
    "            f\"3. Information Synthesis: {synthesis.confidence_level} confidence\",\n",
    "            f\"4. Identified Gaps: {synthesis.information_gaps}\"\n",
    "        ]\n",
    "        \n",
    "        return \"\\n\".join(trace_parts)\n",
    "    \n",
    "    def get_agent_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get current agent status and performance metrics.\"\"\"\n",
    "        \n",
    "        return {\n",
    "            'interaction_count': self.interaction_count,\n",
    "            'success_rate': self.success_rate,\n",
    "            'memory_size': {\n",
    "                'conversation_history': len(self.memory.conversation_history),\n",
    "                'retrieved_context': len(self.memory.retrieved_context),\n",
    "                'reasoning_traces': len(self.memory.reasoning_traces),\n",
    "                'learned_facts': len(self.memory.learned_facts)\n",
    "            },\n",
    "            'last_interactions': self.memory.action_history[-5:] if self.memory.action_history else []\n",
    "        }\n",
    "\n",
    "# Initialize the RAG agent\n",
    "rag_agent = AdvancedRAGAgent(retriever)\n",
    "\n",
    "print_result(\"Advanced RAG Agent initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d779cb5",
   "metadata": {},
   "source": [
    "## Testing the RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Testing RAG Agent\", \"Demonstrating agent capabilities with various queries\")\n",
    "\n",
    "# Test queries of different types\n",
    "test_queries = [\n",
    "    \"What is machine learning and how does it work?\",\n",
    "    \"Can you explain the business applications of AI?\",\n",
    "    \"How do neural networks process information?\",\n",
    "    \"What are the ethical considerations in AI development?\",\n",
    "    \"Follow up: Can you give me specific examples of ethical AI frameworks?\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query {i}: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    try:\n",
    "        result = rag_agent(query)\n",
    "        \n",
    "        print_result(f\"Answer: {result.answer}\", \"Response\")\n",
    "        print_result(f\"Confidence: {result.confidence}\", \"Confidence\")\n",
    "        print_result(f\"Query Type: {result.query_type}\", \"Analysis\")\n",
    "        print_result(f\"Sources: {', '.join(result.retrieved_sources)}\", \"Sources\")\n",
    "        \n",
    "        if result.information_gaps:\n",
    "            print_result(f\"Information Gaps: {result.information_gaps}\", \"Gaps\")\n",
    "        \n",
    "        if result.follow_up_suggestions:\n",
    "            print_result(f\"Follow-up Suggestions: {result.follow_up_suggestions}\", \"Suggestions\")\n",
    "        \n",
    "        print(\"\\nReasoning Trace:\")\n",
    "        print(result.reasoning_trace)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print_error(f\"Error processing query {i}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get agent status\n",
    "status = rag_agent.get_agent_status()\n",
    "\n",
    "print_result(f\"Total Interactions: {status['interaction_count']}\", \"Statistics\")\n",
    "print_result(f\"Success Rate: {status['success_rate']:.2%}\", \"Performance\")\n",
    "print_result(f\"Memory Usage: {status['memory_size']}\", \"Memory\")\n",
    "\n",
    "if status['last_interactions']:\n",
    "    print(\"\\nRecent Interactions:\")\n",
    "    for interaction in status['last_interactions']:\n",
    "        print(f\"  - {interaction['query'][:50]}... | Success: {interaction['success']} | Confidence: {interaction['confidence']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34fc1eb",
   "metadata": {},
   "source": [
    "## Agent Self-Improvement and Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfImprovingRAGAgent(AdvancedRAGAgent):\n",
    "    \"\"\"RAG agent with self-improvement capabilities.\"\"\"\n",
    "    \n",
    "    def __init__(self, retriever: IntelligentRetriever):\n",
    "        super().__init__(retriever)\n",
    "        \n",
    "        # Self-improvement tracking\n",
    "        self.performance_history = []\n",
    "        self.strategy_effectiveness = defaultdict(list)\n",
    "        \n",
    "        # Adaptive parameters\n",
    "        self.confidence_threshold = 0.7\n",
    "        self.retrieval_top_k = 3\n",
    "        self.memory_consolidation_interval = 10\n",
    "    \n",
    "    def forward(self, query: str) -> dspy.Prediction:\n",
    "        \"\"\"Enhanced forward with self-improvement.\"\"\"\n",
    "        \n",
    "        # Call parent implementation\n",
    "        result = super().forward(query)\n",
    "        \n",
    "        # Track performance for self-improvement\n",
    "        self._track_performance(query, result)\n",
    "        \n",
    "        # Periodically consolidate memory and adapt\n",
    "        if self.interaction_count % self.memory_consolidation_interval == 0:\n",
    "            self._consolidate_memory()\n",
    "            self._adapt_parameters()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _track_performance(self, query: str, result):\n",
    "        \"\"\"Track performance metrics for learning.\"\"\"\n",
    "        \n",
    "        # Extract confidence score\n",
    "        try:\n",
    "            confidence_score = float(result.confidence.split('%')[0] if '%' in result.confidence else result.confidence)\n",
    "        except:\n",
    "            confidence_score = 0.5  # Default\n",
    "        \n",
    "        # Performance record\n",
    "        performance_record = {\n",
    "            'query_type': result.query_type,\n",
    "            'confidence': confidence_score,\n",
    "            'answer_length': len(result.answer),\n",
    "            'sources_used': len(result.retrieved_sources),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.performance_history.append(performance_record)\n",
    "        \n",
    "        # Track strategy effectiveness\n",
    "        self.strategy_effectiveness[result.query_type].append(confidence_score)\n",
    "    \n",
    "    def _consolidate_memory(self):\n",
    "        \"\"\"Consolidate and optimize memory usage.\"\"\"\n",
    "        \n",
    "        print_step(\"Memory Consolidation\", \"Optimizing agent memory\")\n",
    "        \n",
    "        # Consolidate conversation history (keep last 20 interactions)\n",
    "        if len(self.memory.conversation_history) > 40:  # 20 Q&A pairs\n",
    "            self.memory.conversation_history = self.memory.conversation_history[-40:]\n",
    "        \n",
    "        # Consolidate retrieved context (remove duplicates and low-value content)\n",
    "        unique_context = list(set(self.memory.retrieved_context))\n",
    "        self.memory.retrieved_context = unique_context[-50:]  # Keep last 50 unique documents\n",
    "        \n",
    "        # Extract key learnings from reasoning traces\n",
    "        if len(self.memory.reasoning_traces) > 20:\n",
    "            # Keep successful patterns and recent traces\n",
    "            self.memory.reasoning_traces = self.memory.reasoning_traces[-20:]\n",
    "        \n",
    "        print_result(\"Memory consolidation completed\")\n",
    "    \n",
    "    def _adapt_parameters(self):\n",
    "        \"\"\"Adapt agent parameters based on performance.\"\"\"\n",
    "        \n",
    "        if len(self.performance_history) < 5:\n",
    "            return\n",
    "        \n",
    "        print_step(\"Parameter Adaptation\", \"Optimizing agent parameters\")\n",
    "        \n",
    "        # Analyze recent performance\n",
    "        recent_performance = self.performance_history[-10:]\n",
    "        avg_confidence = np.mean([p['confidence'] for p in recent_performance])\n",
    "        avg_sources = np.mean([p['sources_used'] for p in recent_performance])\n",
    "        \n",
    "        # Adapt confidence threshold\n",
    "        if avg_confidence < 0.6:\n",
    "            self.confidence_threshold = max(0.5, self.confidence_threshold - 0.05)\n",
    "            print_result(f\"Lowered confidence threshold to {self.confidence_threshold}\")\n",
    "        elif avg_confidence > 0.8:\n",
    "            self.confidence_threshold = min(0.9, self.confidence_threshold + 0.05)\n",
    "            print_result(f\"Raised confidence threshold to {self.confidence_threshold}\")\n",
    "        \n",
    "        # Adapt retrieval parameters\n",
    "        if avg_sources < 2:\n",
    "            self.retrieval_top_k = min(5, self.retrieval_top_k + 1)\n",
    "            print_result(f\"Increased retrieval top_k to {self.retrieval_top_k}\")\n",
    "        elif avg_sources > 4:\n",
    "            self.retrieval_top_k = max(2, self.retrieval_top_k - 1)\n",
    "            print_result(f\"Decreased retrieval top_k to {self.retrieval_top_k}\")\n",
    "    \n",
    "    def get_learning_insights(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get insights about agent learning and performance.\"\"\"\n",
    "        \n",
    "        insights = {\n",
    "            'performance_trends': self._analyze_performance_trends(),\n",
    "            'strategy_effectiveness': self._analyze_strategy_effectiveness(),\n",
    "            'adaptation_history': self._get_adaptation_history(),\n",
    "            'current_parameters': {\n",
    "                'confidence_threshold': self.confidence_threshold,\n",
    "                'retrieval_top_k': self.retrieval_top_k,\n",
    "                'memory_consolidation_interval': self.memory_consolidation_interval\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def _analyze_performance_trends(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze performance trends over time.\"\"\"\n",
    "        \n",
    "        if len(self.performance_history) < 5:\n",
    "            return {'status': 'insufficient_data'}\n",
    "        \n",
    "        # Calculate trends\n",
    "        confidences = [p['confidence'] for p in self.performance_history]\n",
    "        recent_avg = np.mean(confidences[-5:])\n",
    "        overall_avg = np.mean(confidences)\n",
    "        \n",
    "        return {\n",
    "            'overall_average_confidence': overall_avg,\n",
    "            'recent_average_confidence': recent_avg,\n",
    "            'improvement_trend': 'improving' if recent_avg > overall_avg else 'declining',\n",
    "            'total_interactions': len(self.performance_history)\n",
    "        }\n",
    "    \n",
    "    def _analyze_strategy_effectiveness(self) -> Dict[str, float]:\n",
    "        \"\"\"Analyze effectiveness of different strategies.\"\"\"\n",
    "        \n",
    "        effectiveness = {}\n",
    "        for strategy, scores in self.strategy_effectiveness.items():\n",
    "            if scores:\n",
    "                effectiveness[strategy] = np.mean(scores)\n",
    "        \n",
    "        return effectiveness\n",
    "    \n",
    "    def _get_adaptation_history(self) -> List[str]:\n",
    "        \"\"\"Get history of parameter adaptations.\"\"\"\n",
    "        \n",
    "        # This would be more sophisticated in a real implementation\n",
    "        return [\n",
    "            f\"Confidence threshold: {self.confidence_threshold}\",\n",
    "            f\"Retrieval top_k: {self.retrieval_top_k}\",\n",
    "            f\"Memory consolidation interval: {self.memory_consolidation_interval}\"\n",
    "        ]\n",
    "\n",
    "# Initialize self-improving agent\n",
    "self_improving_agent = SelfImprovingRAGAgent(retriever)\n",
    "\n",
    "print_result(\"Self-improving RAG Agent initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ccabe",
   "metadata": {},
   "source": [
    "## Testing Self-Improvement Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a736ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Testing Self-Improvement\", \"Running queries to demonstrate learning\")\n",
    "\n",
    "# Extended test with varied queries to trigger learning\n",
    "learning_queries = [\n",
    "    \"What are the fundamentals of machine learning?\",\n",
    "    \"How do businesses implement AI solutions?\",\n",
    "    \"Can you explain deep learning architectures?\",\n",
    "    \"What are the challenges in AI ethics?\",\n",
    "    \"How does natural language processing work?\",\n",
    "    \"What is the future of artificial intelligence?\",\n",
    "    \"Can you compare different ML algorithms?\",\n",
    "    \"How do recommendation systems function?\",\n",
    "    \"What role does data play in AI success?\",\n",
    "    \"How can AI be applied in healthcare?\",\n",
    "    \"What are the limitations of current AI?\",\n",
    "    \"How do we ensure AI fairness and transparency?\"\n",
    "]\n",
    "\n",
    "# Process queries and track learning\n",
    "for i, query in enumerate(learning_queries, 1):\n",
    "    print(f\"\\nQuery {i}: {query}\")\n",
    "    \n",
    "    try:\n",
    "        result = self_improving_agent(query)\n",
    "        print(f\"Response confidence: {result.confidence}\")\n",
    "        \n",
    "        # Show consolidation messages when they occur\n",
    "        if i % 10 == 0:\n",
    "            print(\"[Agent performed memory consolidation and parameter adaptation]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print_error(f\"Error in query {i}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEARNING INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get learning insights\n",
    "insights = self_improving_agent.get_learning_insights()\n",
    "\n",
    "print_step(\"Performance Analysis\")\n",
    "trends = insights['performance_trends']\n",
    "if 'overall_average_confidence' in trends:\n",
    "    print_result(f\"Overall Average Confidence: {trends['overall_average_confidence']:.2%}\")\n",
    "    print_result(f\"Recent Average Confidence: {trends['recent_average_confidence']:.2%}\")\n",
    "    print_result(f\"Trend: {trends['improvement_trend']}\")\n",
    "\n",
    "print_step(\"Strategy Effectiveness\")\n",
    "for strategy, effectiveness in insights['strategy_effectiveness'].items():\n",
    "    print_result(f\"{strategy}: {effectiveness:.2%}\")\n",
    "\n",
    "print_step(\"Current Parameters\")\n",
    "for param, value in insights['current_parameters'].items():\n",
    "    print_result(f\"{param}: {value}\")\n",
    "\n",
    "# Compare with initial agent\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "initial_status = rag_agent.get_agent_status()\n",
    "improved_status = self_improving_agent.get_agent_status()\n",
    "\n",
    "print_step(\"Performance Comparison\")\n",
    "print_result(f\"Initial Agent Success Rate: {initial_status['success_rate']:.2%}\")\n",
    "print_result(f\"Self-Improving Agent Success Rate: {improved_status['success_rate']:.2%}\")\n",
    "print_result(f\"Improvement: {(improved_status['success_rate'] - initial_status['success_rate']):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32535e",
   "metadata": {},
   "source": [
    "## Advanced Agent Features Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b283981",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_step(\"Advanced Features Demo\", \"Demonstrating specialized agent capabilities\")\n",
    "\n",
    "# 1. Multi-turn conversation with context\n",
    "print(\"\\n1. Multi-turn Conversation:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "conversation_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Can you give me specific examples?\",\n",
    "    \"How does this compare to traditional programming?\",\n",
    "    \"What are the main challenges in implementing ML?\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(conversation_queries, 1):\n",
    "    print(f\"\\nTurn {i}: {query}\")\n",
    "    result = self_improving_agent(query)\n",
    "    print(f\"Agent: {result.answer[:150]}...\")\n",
    "    if result.follow_up_suggestions:\n",
    "        print(f\"Suggestions: {result.follow_up_suggestions}\")\n",
    "\n",
    "# 2. Complex analytical query\n",
    "print(\"\\n\\n2. Complex Analytical Query:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "complex_query = \"Analyze the relationship between artificial intelligence, machine learning, and deep learning. How do they differ and how do they work together in modern applications?\"\n",
    "result = self_improving_agent(complex_query)\n",
    "\n",
    "print_result(f\"Query Type: {result.query_type}\")\n",
    "print_result(f\"Answer: {result.answer}\")\n",
    "print_result(f\"Confidence: {result.confidence}\")\n",
    "print_result(f\"Sources Used: {len(result.retrieved_sources)}\")\n",
    "\n",
    "# 3. Information gap identification\n",
    "print(\"\\n\\n3. Information Gap Identification:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "gap_query = \"What are the latest developments in quantum machine learning and their implications for cryptography?\"\n",
    "result = self_improving_agent(gap_query)\n",
    "\n",
    "print_result(f\"Answer: {result.answer}\")\n",
    "if result.information_gaps:\n",
    "    print_result(f\"Identified Gaps: {result.information_gaps}\")\n",
    "if result.follow_up_suggestions:\n",
    "    print_result(f\"Suggestions: {result.follow_up_suggestions}\")\n",
    "\n",
    "# 4. Agent introspection\n",
    "print(\"\\n\\n4. Agent Self-Analysis:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "final_status = self_improving_agent.get_agent_status()\n",
    "final_insights = self_improving_agent.get_learning_insights()\n",
    "\n",
    "print_step(\"Final Agent Statistics\")\n",
    "print_result(f\"Total Interactions: {final_status['interaction_count']}\")\n",
    "print_result(f\"Final Success Rate: {final_status['success_rate']:.2%}\")\n",
    "print_result(f\"Memory Components: {final_status['memory_size']}\")\n",
    "\n",
    "if 'performance_trends' in final_insights and 'improvement_trend' in final_insights['performance_trends']:\n",
    "    print_result(f\"Learning Trend: {final_insights['performance_trends']['improvement_trend']}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ RAG Agent demonstration completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af67e6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to build sophisticated RAG agents using DSPy:\n",
    "\n",
    "### Key Features Implemented:\n",
    "\n",
    "1. **Intelligent Retrieval**: Context-aware document retrieval with relevance scoring\n",
    "2. **Multi-step Reasoning**: Query analysis, action planning, and information synthesis\n",
    "3. **Memory Management**: Conversation history, retrieved context, and learned facts\n",
    "4. **Self-Improvement**: Adaptive parameters and continuous learning\n",
    "5. **Agent Transparency**: Detailed reasoning traces and confidence scoring\n",
    "\n",
    "### DSPy Features Utilized:\n",
    "\n",
    "- **Signatures**: Structured task definitions for each agent component\n",
    "- **Chain of Thought**: Step-by-step reasoning for complex tasks\n",
    "- **Modular Design**: Composable agent architecture\n",
    "- **Memory Integration**: Persistent state across interactions\n",
    "\n",
    "### Advanced Capabilities:\n",
    "\n",
    "- **Context-Aware Retrieval**: Considers conversation history and previous interactions\n",
    "- **Adaptive Learning**: Adjusts parameters based on performance feedback\n",
    "- **Multi-turn Conversations**: Maintains context across dialog turns\n",
    "- **Gap Identification**: Recognizes limitations in available information\n",
    "- **Performance Tracking**: Monitors and improves agent effectiveness\n",
    "\n",
    "### Real-world Applications:\n",
    "\n",
    "- **Customer Support**: Intelligent help desk agents with memory\n",
    "- **Research Assistance**: Academic and technical research support\n",
    "- **Knowledge Management**: Organizational knowledge bases and Q&A\n",
    "- **Educational Tutoring**: Adaptive learning and personalized instruction\n",
    "- **Business Intelligence**: Data-driven insights and recommendations\n",
    "\n",
    "This RAG agent architecture demonstrates how DSPy enables building sophisticated, adaptive AI systems that can learn and improve over time while maintaining transparency and reliability."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
