{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d39c22",
   "metadata": {},
   "source": [
    "# Saving and Loading DSPy Programs\n",
    "\n",
    "This tutorial demonstrates how to save and load DSPy programs, including modules, optimized parameters, and complete pipelines.\n",
    "\n",
    "## What You'll Learn:\n",
    "- How to save and load DSPy modules\n",
    "- Persisting optimized parameters\n",
    "- Version management for DSPy programs\n",
    "- Best practices for model serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b945c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import dspy\n",
    "except ImportError:\n",
    "    install_package(\"dspy\")\n",
    "    import dspy\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f439b",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure DSPy\n",
    "lm = dspy.LM('openai/gpt-4o-mini', api_key=os.getenv('OPENAI_API_KEY'))\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Create a directory for saving models\n",
    "models_dir = Path(\"saved_models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"DSPy configured successfully!\")\n",
    "print(f\"Models will be saved to: {models_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26a11e",
   "metadata": {},
   "source": [
    "## Creating a Sample DSPy Program\n",
    "\n",
    "Let's create a complete DSPy program that we can save and load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswerSignature(dspy.Signature):\n",
    "    \"\"\"Answer a question with a comprehensive response.\"\"\"\n",
    "    \n",
    "    question: str = dspy.InputField(desc=\"The question to answer\")\n",
    "    context: str = dspy.InputField(desc=\"Relevant context information\")\n",
    "    answer: str = dspy.OutputField(desc=\"A comprehensive answer\")\n",
    "    confidence: float = dspy.OutputField(desc=\"Confidence score (0.0-1.0)\")\n",
    "\n",
    "class FactCheckSignature(dspy.Signature):\n",
    "    \"\"\"Verify the accuracy of an answer.\"\"\"\n",
    "    \n",
    "    question: str = dspy.InputField(desc=\"The original question\")\n",
    "    answer: str = dspy.InputField(desc=\"The answer to verify\")\n",
    "    is_accurate: bool = dspy.OutputField(desc=\"Whether the answer is accurate\")\n",
    "    explanation: str = dspy.OutputField(desc=\"Explanation of the verification\")\n",
    "\n",
    "class QuestionAnsweringSystem(dspy.Module):\n",
    "    \"\"\"A complete question answering system with fact-checking.\"\"\"\n",
    "    \n",
    "    def __init__(self, use_fact_check: bool = True):\n",
    "        super().__init__()\n",
    "        self.use_fact_check = use_fact_check\n",
    "        self.answerer = dspy.ChainOfThought(QuestionAnswerSignature)\n",
    "        if use_fact_check:\n",
    "            self.fact_checker = dspy.ChainOfThought(FactCheckSignature)\n",
    "        \n",
    "        # Store configuration\n",
    "        self.config = {\n",
    "            'use_fact_check': use_fact_check,\n",
    "            'created_at': datetime.datetime.now().isoformat(),\n",
    "            'version': '1.0'\n",
    "        }\n",
    "    \n",
    "    def forward(self, question: str, context: str = \"\") -> dspy.Prediction:\n",
    "        # Generate initial answer\n",
    "        answer_result = self.answerer(\n",
    "            question=question,\n",
    "            context=context\n",
    "        )\n",
    "        \n",
    "        # Fact check if enabled\n",
    "        if self.use_fact_check:\n",
    "            fact_check_result = self.fact_checker(\n",
    "                question=question,\n",
    "                answer=answer_result.answer\n",
    "            )\n",
    "            \n",
    "            return dspy.Prediction(\n",
    "                answer=answer_result.answer,\n",
    "                confidence=float(answer_result.confidence),\n",
    "                is_accurate=fact_check_result.is_accurate,\n",
    "                fact_check_explanation=fact_check_result.explanation\n",
    "            )\n",
    "        else:\n",
    "            return dspy.Prediction(\n",
    "                answer=answer_result.answer,\n",
    "                confidence=float(answer_result.confidence)\n",
    "            )\n",
    "\n",
    "# Create and test the system\n",
    "qa_system = QuestionAnsweringSystem(use_fact_check=True)\n",
    "\n",
    "test_question = \"What is the capital of France?\"\n",
    "test_context = \"France is a country in Western Europe.\"\n",
    "\n",
    "result = qa_system(question=test_question, context=test_context)\n",
    "print(f\"Question: {test_question}\")\n",
    "print(f\"Answer: {result.answer}\")\n",
    "print(f\"Confidence: {result.confidence}\")\n",
    "print(f\"Fact Check: {result.is_accurate}\")\n",
    "print(f\"Explanation: {result.fact_check_explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc03fe",
   "metadata": {},
   "source": [
    "## Basic Saving and Loading\n",
    "\n",
    "DSPy provides built-in methods for saving and loading modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e400f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the QA system using DSPy's built-in save method\n",
    "basic_save_path = models_dir / \"qa_system_basic.json\"\n",
    "\n",
    "# Save the module\n",
    "qa_system.save(str(basic_save_path))\n",
    "print(f\"Model saved to: {basic_save_path}\")\n",
    "\n",
    "# Load the module\n",
    "loaded_qa_system = QuestionAnsweringSystem(use_fact_check=True)\n",
    "loaded_qa_system.load(str(basic_save_path))\n",
    "\n",
    "# Test the loaded system\n",
    "loaded_result = loaded_qa_system(\n",
    "    question=\"What is the largest planet in our solar system?\",\n",
    "    context=\"The solar system contains eight planets.\"\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded model test:\")\n",
    "print(f\"Answer: {loaded_result.answer}\")\n",
    "print(f\"Confidence: {loaded_result.confidence}\")\n",
    "print(f\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e6a2ab",
   "metadata": {},
   "source": [
    "## Advanced Saving with Metadata\n",
    "\n",
    "For production use, you'll want to save additional metadata along with your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"Manager for saving and loading DSPy models with metadata.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir: str = \"saved_models\"):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.base_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def save_model(self, model: dspy.Module, model_name: str, \n",
    "                   version: str = \"1.0\", metadata: Dict[str, Any] = None) -> str:\n",
    "        \"\"\"Save a DSPy model with metadata.\"\"\"\n",
    "        \n",
    "        # Create model directory\n",
    "        model_dir = self.base_dir / model_name / version\n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save the model\n",
    "        model_path = model_dir / \"model.json\"\n",
    "        model.save(str(model_path))\n",
    "        \n",
    "        # Prepare metadata\n",
    "        full_metadata = {\n",
    "            'model_name': model_name,\n",
    "            'version': version,\n",
    "            'saved_at': datetime.datetime.now().isoformat(),\n",
    "            'model_class': model.__class__.__name__,\n",
    "            'model_config': getattr(model, 'config', {}),\n",
    "            'dspy_version': dspy.__version__ if hasattr(dspy, '__version__') else 'unknown'\n",
    "        }\n",
    "        \n",
    "        if metadata:\n",
    "            full_metadata.update(metadata)\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_path = model_dir / \"metadata.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(full_metadata, f, indent=2)\n",
    "        \n",
    "        # Save model architecture (for reference)\n",
    "        architecture_path = model_dir / \"architecture.txt\"\n",
    "        with open(architecture_path, 'w') as f:\n",
    "            f.write(f\"Model Class: {model.__class__.__name__}\\n\")\n",
    "            f.write(f\"Module Attributes:\\n\")\n",
    "            for attr_name in dir(model):\n",
    "                if not attr_name.startswith('_') and hasattr(model, attr_name):\n",
    "                    attr = getattr(model, attr_name)\n",
    "                    if isinstance(attr, dspy.Module):\n",
    "                        f.write(f\"  - {attr_name}: {attr.__class__.__name__}\\n\")\n",
    "        \n",
    "        print(f\"Model saved to: {model_dir}\")\n",
    "        return str(model_dir)\n",
    "    \n",
    "    def load_model(self, model_class, model_name: str, version: str = \"latest\") -> tuple:\n",
    "        \"\"\"Load a DSPy model with metadata.\"\"\"\n",
    "        \n",
    "        model_base_dir = self.base_dir / model_name\n",
    "        \n",
    "        if version == \"latest\":\n",
    "            # Find the latest version\n",
    "            if not model_base_dir.exists():\n",
    "                raise FileNotFoundError(f\"Model {model_name} not found\")\n",
    "            \n",
    "            versions = [d.name for d in model_base_dir.iterdir() if d.is_dir()]\n",
    "            if not versions:\n",
    "                raise FileNotFoundError(f\"No versions found for model {model_name}\")\n",
    "            \n",
    "            # Sort versions (simple string sort, could be improved)\n",
    "            version = sorted(versions)[-1]\n",
    "        \n",
    "        model_dir = model_base_dir / version\n",
    "        \n",
    "        if not model_dir.exists():\n",
    "            raise FileNotFoundError(f\"Model {model_name} version {version} not found\")\n",
    "        \n",
    "        # Load metadata\n",
    "        metadata_path = model_dir / \"metadata.json\"\n",
    "        if metadata_path.exists():\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        # Initialize model (you need to provide the class)\n",
    "        # In practice, you might store initialization parameters in metadata\n",
    "        if hasattr(model_class, '__init__'):\n",
    "            # Try to reconstruct from config if available\n",
    "            config = metadata.get('model_config', {})\n",
    "            model = model_class(**config) if config else model_class()\n",
    "        else:\n",
    "            model = model_class()\n",
    "        \n",
    "        # Load the model state\n",
    "        model_path = model_dir / \"model.json\"\n",
    "        model.load(str(model_path))\n",
    "        \n",
    "        print(f\"Model loaded from: {model_dir}\")\n",
    "        return model, metadata\n",
    "    \n",
    "    def list_models(self) -> Dict[str, list]:\n",
    "        \"\"\"List all saved models and their versions.\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        for model_dir in self.base_dir.iterdir():\n",
    "            if model_dir.is_dir():\n",
    "                versions = [v.name for v in model_dir.iterdir() if v.is_dir()]\n",
    "                models[model_dir.name] = sorted(versions)\n",
    "        \n",
    "        return models\n",
    "\n",
    "# Test the model manager\n",
    "manager = ModelManager()\n",
    "\n",
    "# Save with metadata\n",
    "metadata = {\n",
    "    'description': 'Question answering system with fact checking',\n",
    "    'training_data': 'General knowledge',\n",
    "    'performance_metrics': {\n",
    "        'accuracy': 0.85,\n",
    "        'latency_ms': 1200\n",
    "    },\n",
    "    'author': 'DSPy Tutorial',\n",
    "    'tags': ['qa', 'fact-check', 'production']\n",
    "}\n",
    "\n",
    "save_path = manager.save_model(\n",
    "    model=qa_system,\n",
    "    model_name=\"question_answering_system\",\n",
    "    version=\"1.0\",\n",
    "    metadata=metadata\n",
    ")\n",
    "\n",
    "# List saved models\n",
    "print(\"\\nSaved models:\")\n",
    "for model_name, versions in manager.list_models().items():\n",
    "    print(f\"  {model_name}: {versions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053ceac",
   "metadata": {},
   "source": [
    "## Loading and Version Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model, loaded_metadata = manager.load_model(\n",
    "    model_class=QuestionAnsweringSystem,\n",
    "    model_name=\"question_answering_system\",\n",
    "    version=\"latest\"\n",
    ")\n",
    "\n",
    "print(\"Loaded model metadata:\")\n",
    "print(json.dumps(loaded_metadata, indent=2))\n",
    "\n",
    "# Test the loaded model\n",
    "test_result = loaded_model(\n",
    "    question=\"Who invented the telephone?\",\n",
    "    context=\"The telephone was invented in the 19th century.\"\n",
    ")\n",
    "\n",
    "print(f\"\\nTest of loaded model:\")\n",
    "print(f\"Answer: {test_result.answer}\")\n",
    "print(f\"Confidence: {test_result.confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0b3c3",
   "metadata": {},
   "source": [
    "## Saving Optimized Models\n",
    "\n",
    "When you've optimized a model using DSPy optimizers, you'll want to save the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1842d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some sample training data\n",
    "sample_training_data = [\n",
    "    dspy.Example(\n",
    "        question=\"What is the capital of Italy?\",\n",
    "        context=\"Italy is a country in Southern Europe.\",\n",
    "        answer=\"Rome\"\n",
    "    ).with_inputs('question', 'context'),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"What is the largest ocean?\",\n",
    "        context=\"Earth has several large bodies of water.\",\n",
    "        answer=\"Pacific Ocean\"\n",
    "    ).with_inputs('question', 'context'),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"Who wrote Romeo and Juliet?\",\n",
    "        context=\"Romeo and Juliet is a famous play.\",\n",
    "        answer=\"William Shakespeare\"\n",
    "    ).with_inputs('question', 'context')\n",
    "]\n",
    "\n",
    "# Define a simple evaluation metric\n",
    "def simple_accuracy(example, pred, trace=None):\n",
    "    \"\"\"Simple accuracy metric for demonstration.\"\"\"\n",
    "    return example.answer.lower() in pred.answer.lower()\n",
    "\n",
    "# Create a new model for optimization\n",
    "trainable_qa_system = QuestionAnsweringSystem(use_fact_check=False)  # Simpler for demo\n",
    "\n",
    "# Set up optimizer (using a simple one for demo)\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "optimizer = BootstrapFewShot(\n",
    "    metric=simple_accuracy,\n",
    "    max_bootstrapped_demos=2,\n",
    "    max_labeled_demos=2\n",
    ")\n",
    "\n",
    "print(\"Optimizing model...\")\n",
    "try:\n",
    "    optimized_qa_system = optimizer.compile(\n",
    "        trainable_qa_system,\n",
    "        trainset=sample_training_data\n",
    "    )\n",
    "    \n",
    "    # Save the optimized model\n",
    "    optimized_metadata = {\n",
    "        'description': 'Optimized question answering system',\n",
    "        'optimizer': 'BootstrapFewShot',\n",
    "        'training_examples': len(sample_training_data),\n",
    "        'optimization_date': datetime.datetime.now().isoformat(),\n",
    "        'base_model': 'question_answering_system',\n",
    "        'optimization_config': {\n",
    "            'max_bootstrapped_demos': 2,\n",
    "            'max_labeled_demos': 2,\n",
    "            'metric': 'simple_accuracy'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    optimized_save_path = manager.save_model(\n",
    "        model=optimized_qa_system,\n",
    "        model_name=\"question_answering_system_optimized\",\n",
    "        version=\"1.0\",\n",
    "        metadata=optimized_metadata\n",
    "    )\n",
    "    \n",
    "    print(f\"Optimized model saved successfully!\")\n",
    "    \n",
    "    # Test the optimized model\n",
    "    optimized_result = optimized_qa_system(\n",
    "        question=\"What is the smallest planet?\",\n",
    "        context=\"The solar system has planets of various sizes.\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nOptimized model test:\")\n",
    "    print(f\"Answer: {optimized_result.answer}\")\n",
    "    print(f\"Confidence: {optimized_result.confidence}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Optimization failed (this is expected in demo): {e}\")\n",
    "    print(\"In practice, you would have proper training data and evaluation setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400c500",
   "metadata": {},
   "source": [
    "## Model Versioning and Deployment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDeploymentPipeline:\n",
    "    \"\"\"Pipeline for model versioning and deployment.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_manager: ModelManager):\n",
    "        self.manager = model_manager\n",
    "        self.deployment_dir = self.manager.base_dir / \"deployments\"\n",
    "        self.deployment_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def create_deployment(self, model_name: str, version: str, \n",
    "                         deployment_name: str = \"production\") -> str:\n",
    "        \"\"\"Create a deployment of a specific model version.\"\"\"\n",
    "        \n",
    "        # Create deployment directory\n",
    "        deployment_path = self.deployment_dir / deployment_name\n",
    "        deployment_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Copy model files\n",
    "        source_dir = self.manager.base_dir / model_name / version\n",
    "        \n",
    "        if not source_dir.exists():\n",
    "            raise FileNotFoundError(f\"Model {model_name} version {version} not found\")\n",
    "        \n",
    "        # Copy files\n",
    "        import shutil\n",
    "        for file_path in source_dir.glob(\"*\"):\n",
    "            if file_path.is_file():\n",
    "                shutil.copy2(file_path, deployment_path / file_path.name)\n",
    "        \n",
    "        # Create deployment manifest\n",
    "        manifest = {\n",
    "            'deployment_name': deployment_name,\n",
    "            'model_name': model_name,\n",
    "            'model_version': version,\n",
    "            'deployed_at': datetime.datetime.now().isoformat(),\n",
    "            'deployment_id': f\"{model_name}_{version}_{deployment_name}\"\n",
    "        }\n",
    "        \n",
    "        manifest_path = deployment_path / \"deployment_manifest.json\"\n",
    "        with open(manifest_path, 'w') as f:\n",
    "            json.dump(manifest, f, indent=2)\n",
    "        \n",
    "        print(f\"Deployment '{deployment_name}' created: {deployment_path}\")\n",
    "        return str(deployment_path)\n",
    "    \n",
    "    def load_deployment(self, deployment_name: str, model_class):\n",
    "        \"\"\"Load a deployed model.\"\"\"\n",
    "        \n",
    "        deployment_path = self.deployment_dir / deployment_name\n",
    "        \n",
    "        if not deployment_path.exists():\n",
    "            raise FileNotFoundError(f\"Deployment '{deployment_name}' not found\")\n",
    "        \n",
    "        # Load manifest\n",
    "        manifest_path = deployment_path / \"deployment_manifest.json\"\n",
    "        with open(manifest_path, 'r') as f:\n",
    "            manifest = json.load(f)\n",
    "        \n",
    "        # Load metadata\n",
    "        metadata_path = deployment_path / \"metadata.json\"\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        # Load model\n",
    "        config = metadata.get('model_config', {})\n",
    "        model = model_class(**config) if config else model_class()\n",
    "        \n",
    "        model_path = deployment_path / \"model.json\"\n",
    "        model.load(str(model_path))\n",
    "        \n",
    "        return model, manifest, metadata\n",
    "    \n",
    "    def list_deployments(self) -> Dict[str, Dict]:\n",
    "        \"\"\"List all deployments.\"\"\"\n",
    "        deployments = {}\n",
    "        \n",
    "        for deployment_dir in self.deployment_dir.iterdir():\n",
    "            if deployment_dir.is_dir():\n",
    "                manifest_path = deployment_dir / \"deployment_manifest.json\"\n",
    "                if manifest_path.exists():\n",
    "                    with open(manifest_path, 'r') as f:\n",
    "                        manifest = json.load(f)\n",
    "                    deployments[deployment_dir.name] = manifest\n",
    "        \n",
    "        return deployments\n",
    "\n",
    "# Test deployment pipeline\n",
    "deployment_pipeline = ModelDeploymentPipeline(manager)\n",
    "\n",
    "# Create a production deployment\n",
    "try:\n",
    "    deployment_path = deployment_pipeline.create_deployment(\n",
    "        model_name=\"question_answering_system\",\n",
    "        version=\"1.0\",\n",
    "        deployment_name=\"production\"\n",
    "    )\n",
    "    \n",
    "    # List deployments\n",
    "    print(\"\\nActive deployments:\")\n",
    "    for deployment_name, manifest in deployment_pipeline.list_deployments().items():\n",
    "        print(f\"  {deployment_name}: {manifest['model_name']} v{manifest['model_version']}\")\n",
    "    \n",
    "    # Load and test production model\n",
    "    prod_model, prod_manifest, prod_metadata = deployment_pipeline.load_deployment(\n",
    "        \"production\",\n",
    "        QuestionAnsweringSystem\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nProduction model loaded successfully!\")\n",
    "    print(f\"Deployment ID: {prod_manifest['deployment_id']}\")\n",
    "    \n",
    "    # Test production model\n",
    "    prod_result = prod_model(\n",
    "        question=\"What is photosynthesis?\",\n",
    "        context=\"Plants use sunlight to create energy.\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nProduction model test:\")\n",
    "    print(f\"Answer: {prod_result.answer}\")\n",
    "    print(f\"Confidence: {prod_result.confidence}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Deployment error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a83fcb",
   "metadata": {},
   "source": [
    "## Best Practices for Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19245094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionModelManager:\n",
    "    \"\"\"Production-ready model manager with additional features.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir: str = \"saved_models\"):\n",
    "        self.manager = ModelManager(base_dir)\n",
    "        self.config_file = Path(base_dir) / \"manager_config.json\"\n",
    "        self.load_config()\n",
    "    \n",
    "    def load_config(self):\n",
    "        \"\"\"Load manager configuration.\"\"\"\n",
    "        if self.config_file.exists():\n",
    "            with open(self.config_file, 'r') as f:\n",
    "                self.config = json.load(f)\n",
    "        else:\n",
    "            self.config = {\n",
    "                'retention_policy': {\n",
    "                    'max_versions_per_model': 5,\n",
    "                    'max_age_days': 90\n",
    "                },\n",
    "                'backup_enabled': True,\n",
    "                'compression': True\n",
    "            }\n",
    "            self.save_config()\n",
    "    \n",
    "    def save_config(self):\n",
    "        \"\"\"Save manager configuration.\"\"\"\n",
    "        with open(self.config_file, 'w') as f:\n",
    "            json.dump(self.config, f, indent=2)\n",
    "    \n",
    "    def save_model_with_validation(self, model: dspy.Module, model_name: str, \n",
    "                                 version: str, metadata: Dict[str, Any] = None,\n",
    "                                 test_cases: list = None) -> str:\n",
    "        \"\"\"Save model with validation and testing.\"\"\"\n",
    "        \n",
    "        # Validate model before saving\n",
    "        if test_cases:\n",
    "            print(\"Validating model before saving...\")\n",
    "            validation_results = []\n",
    "            \n",
    "            for i, test_case in enumerate(test_cases):\n",
    "                try:\n",
    "                    result = model(**test_case['inputs'])\n",
    "                    validation_results.append({\n",
    "                        'test_case': i,\n",
    "                        'success': True,\n",
    "                        'result': str(result)[:100] + \"...\" if len(str(result)) > 100 else str(result)\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    validation_results.append({\n",
    "                        'test_case': i,\n",
    "                        'success': False,\n",
    "                        'error': str(e)\n",
    "                    })\n",
    "            \n",
    "            # Add validation results to metadata\n",
    "            if metadata is None:\n",
    "                metadata = {}\n",
    "            metadata['validation_results'] = validation_results\n",
    "            \n",
    "            # Check if validation passed\n",
    "            success_rate = sum(1 for r in validation_results if r['success']) / len(validation_results)\n",
    "            if success_rate < 0.8:  # Require 80% success rate\n",
    "                raise ValueError(f\"Model validation failed. Success rate: {success_rate:.2%}\")\n",
    "            \n",
    "            print(f\"Validation passed with {success_rate:.2%} success rate\")\n",
    "        \n",
    "        # Save model\n",
    "        save_path = self.manager.save_model(model, model_name, version, metadata)\n",
    "        \n",
    "        # Clean up old versions if needed\n",
    "        self.cleanup_old_versions(model_name)\n",
    "        \n",
    "        return save_path\n",
    "    \n",
    "    def cleanup_old_versions(self, model_name: str):\n",
    "        \"\"\"Clean up old model versions based on retention policy.\"\"\"\n",
    "        max_versions = self.config['retention_policy']['max_versions_per_model']\n",
    "        \n",
    "        model_dir = self.manager.base_dir / model_name\n",
    "        if not model_dir.exists():\n",
    "            return\n",
    "        \n",
    "        versions = [d for d in model_dir.iterdir() if d.is_dir()]\n",
    "        \n",
    "        if len(versions) > max_versions:\n",
    "            # Sort by creation time and keep only the newest ones\n",
    "            versions.sort(key=lambda x: x.stat().st_ctime)\n",
    "            versions_to_remove = versions[:-max_versions]\n",
    "            \n",
    "            for version_dir in versions_to_remove:\n",
    "                print(f\"Removing old version: {version_dir}\")\n",
    "                import shutil\n",
    "                shutil.rmtree(version_dir)\n",
    "    \n",
    "    def backup_models(self, backup_dir: str):\n",
    "        \"\"\"Create a backup of all models.\"\"\"\n",
    "        if not self.config['backup_enabled']:\n",
    "            return\n",
    "        \n",
    "        import shutil\n",
    "        import zipfile\n",
    "        \n",
    "        backup_path = Path(backup_dir)\n",
    "        backup_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        backup_file = backup_path / f\"models_backup_{timestamp}.zip\"\n",
    "        \n",
    "        with zipfile.ZipFile(backup_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for file_path in self.manager.base_dir.rglob(\"*\"):\n",
    "                if file_path.is_file():\n",
    "                    arcname = file_path.relative_to(self.manager.base_dir)\n",
    "                    zipf.write(file_path, arcname)\n",
    "        \n",
    "        print(f\"Backup created: {backup_file}\")\n",
    "        return str(backup_file)\n",
    "\n",
    "# Test production model manager\n",
    "prod_manager = ProductionModelManager()\n",
    "\n",
    "# Define test cases for validation\n",
    "test_cases = [\n",
    "    {\n",
    "        'inputs': {\n",
    "            'question': 'What is 2+2?',\n",
    "            'context': 'Basic arithmetic'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'inputs': {\n",
    "            'question': 'What is the capital of Japan?',\n",
    "            'context': 'Geography question'\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save model with validation\n",
    "try:\n",
    "    validated_save_path = prod_manager.save_model_with_validation(\n",
    "        model=qa_system,\n",
    "        model_name=\"qa_system_validated\",\n",
    "        version=\"1.0\",\n",
    "        metadata={'validation': True, 'production_ready': True},\n",
    "        test_cases=test_cases\n",
    "    )\n",
    "    \n",
    "    print(f\"Model saved with validation: {validated_save_path}\")\n",
    "    \n",
    "    # Create backup\n",
    "    backup_file = prod_manager.backup_models(\"backups\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Validation or saving failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62813d18",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "This tutorial covered comprehensive model saving and loading in DSPy. Here are the key takeaways:\n",
    "\n",
    "### Core Concepts:\n",
    "1. **Basic Save/Load**: Use DSPy's built-in `.save()` and `.load()` methods\n",
    "2. **Metadata Management**: Store important information about models\n",
    "3. **Version Control**: Implement proper versioning for model evolution\n",
    "4. **Deployment Pipeline**: Create systematic deployment processes\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Always include metadata**: Store model version, creation date, performance metrics\n",
    "2. **Validate before saving**: Test models with sample inputs before persistence\n",
    "3. **Version management**: Implement proper versioning and cleanup policies\n",
    "4. **Backup strategy**: Regular backups of important models\n",
    "5. **Deployment isolation**: Separate development and production model storage\n",
    "6. **Documentation**: Include architecture descriptions and usage examples\n",
    "\n",
    "### Production Considerations:\n",
    "\n",
    "- **Security**: Encrypt sensitive model files\n",
    "- **Access control**: Implement proper permissions\n",
    "- **Monitoring**: Track model performance in production\n",
    "- **Rollback capability**: Keep previous versions for quick rollback\n",
    "- **Storage optimization**: Compress large models and clean up old versions\n",
    "\n",
    "### File Structure Example:\n",
    "```\n",
    "saved_models/\n",
    "├── model_name/\n",
    "│   ├── 1.0/\n",
    "│   │   ├── model.json\n",
    "│   │   ├── metadata.json\n",
    "│   │   └── architecture.txt\n",
    "│   └── 1.1/\n",
    "│       ├── model.json\n",
    "│       ├── metadata.json\n",
    "│       └── architecture.txt\n",
    "├── deployments/\n",
    "│   ├── production/\n",
    "│   └── staging/\n",
    "└── backups/\n",
    "```\n",
    "\n",
    "This approach ensures your DSPy models are properly managed, versioned, and ready for production deployment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
